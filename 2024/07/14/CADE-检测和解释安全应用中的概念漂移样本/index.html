<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>CADE: 检测和解释安全应用中的概念漂移样本 | Nanbu's blog</title><meta name="author" content="Nanbu"><meta name="copyright" content="Nanbu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="## 摘要  概念漂移：因攻击者的行为变化，导致部署的模型出现重大失败 提出CADE：1&gt;可以检测偏离现有类别的样本 2&gt;提供解释来解释检测到的偏移  ## 现状  为应对概念漂移，传统解决方法会定期重新训练安全模型，这样需要标注大量新样本，还需要其确定重新训练的时间，费时费力。  ## CADE  思想：判断一个样本在对某个分类的相似度与其他属于该分类的样本相比是否正常  CADE：主要包含一">
<meta property="og:type" content="article">
<meta property="og:title" content="CADE: 检测和解释安全应用中的概念漂移样本">
<meta property="og:url" content="https://nonbliss.github.io/2024/07/14/CADE-%E6%A3%80%E6%B5%8B%E5%92%8C%E8%A7%A3%E9%87%8A%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E6%A6%82%E5%BF%B5%E6%BC%82%E7%A7%BB%E6%A0%B7%E6%9C%AC/index.html">
<meta property="og:site_name" content="Nanbu&#39;s blog">
<meta property="og:description" content="## 摘要  概念漂移：因攻击者的行为变化，导致部署的模型出现重大失败 提出CADE：1&gt;可以检测偏离现有类别的样本 2&gt;提供解释来解释检测到的偏移  ## 现状  为应对概念漂移，传统解决方法会定期重新训练安全模型，这样需要标注大量新样本，还需要其确定重新训练的时间，费时费力。  ## CADE  思想：判断一个样本在对某个分类的相似度与其他属于该分类的样本相比是否正常  CADE：主要包含一">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://nonbliss.github.io/img/tag.png">
<meta property="article:published_time" content="2024-07-14T01:31:48.000Z">
<meta property="article:modified_time" content="2024-07-14T09:30:46.112Z">
<meta property="article:author" content="Nanbu">
<meta property="article:tag" content="Nanbu">
<meta property="article:tag" content="楠布">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://nonbliss.github.io/img/tag.png"><link rel="shortcut icon" href="/img/logow_t.png"><link rel="canonical" href="https://nonbliss.github.io/2024/07/14/CADE-%E6%A3%80%E6%B5%8B%E5%92%8C%E8%A7%A3%E9%87%8A%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E6%A6%82%E5%BF%B5%E6%BC%82%E7%A7%BB%E6%A0%B7%E6%9C%AC/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CADE: 检测和解释安全应用中的概念漂移样本',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-07-14 17:30:46'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/ahzoo.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%A4%B4%E5%83%8Fplus.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/tag.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Nanbu's blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CADE: 检测和解释安全应用中的概念漂移样本</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-07-14T01:31:48.000Z" title="发表于 2024-07-14 09:31:48">2024-07-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-07-14T09:30:46.112Z" title="更新于 2024-07-14 17:30:46">2024-07-14</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span id="" data-flag-title="CADE: 检测和解释安全应用中的概念漂移样本"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container">
## 摘要

概念漂移：因攻击者的行为变化，导致部署的模型出现重大失败
提出CADE：1>可以检测偏离现有类别的样本 2>提供解释来解释检测到的偏移

## 现状

为应对概念漂移，传统解决方法会定期重新训练安全模型，这样需要标注大量新样本，还需要其确定重新训练的时间，费时费力。

## CADE

思想：判断一个样本在对某个分类的相似度与其他属于该分类的样本相比是否正常

CADE：主要包含一个检测器用于检测输入的样本是否产生漂移，包含一个解释器解释检测器筛选出的样本的漂移
![](1.png)

### 检测器
采用对比学习，将高维的样本数据映射到低维，每个类形成紧密的群体。在这个隐空间中，距离函数可以有效地识别新样本从这些群体中漂移开的情况。

首先使用编码器将所有训练样本映射到隐空间中（第2-4行）。对于每个类别 $ i $，我们计算其质心 $ {\mathbf{c}}_{i} $（通过在欧几里得空间中取每个维度的平均值，第5行）。给定一个测试样本 $ {\mathbf{x}}_{t}^{\left( k\right) } $，我们也使用编码器将其映射到隐空间表示 $ {\mathbf{z}}_{t}^{\left( k\right) } $（第14行）。然后，我们计算测试样本与其质心之间的欧氏距离：$ {d}_{i}^{\left( k\right) } = {\begin{Vmatrix}{\mathbf{z}}_{t}^{\left( k\right) } - {\mathbf{c}}_{i}\end{Vmatrix}}_{2} $（第16行）。根据其到质心的距离，我们确定这个测试样本是否对于 $ N $ 个类别中的每一个都是分布外的。在这里，我们根据样本到质心的距离而不是样本到最近训练样本的距离做出决策。这是因为后一种选择很容易受到训练数据中的异常点的影响。

为了根据 $ {d}_{i}^{\left( k\right) } $ 确定异常点，挑战在于不同类别的紧密度可能不同，因此需要不同的距离阈值。而不是手动为每个类别设置绝对距离阈值，我们使用了一种称为中位数绝对偏差（MAD）[40]的方法。想法是通过计算 $ {\mathrm{{MAD}}}_{i} $（第6-10行）来估计每个类别的数据分布 $ i $，它是中位数距离 $ {d}_{i}^{\left( j\right) }\left( {j = 1,\ldots ,{n}_{i}}\right) $ 的绝对偏差。在这里 $ {d}_{i}^{\left( j\right) } $ 表示类别 $ i $ 中每个样本与其质心的潜在距离，以及 $ {n}_{i} $ 是类别 $ i $ 中样本的数量（第7行）。然后基于 $ {\mathrm{{MAD}}}_{i} $，我们可以确定 $ {d}_{i}^{\left( k\right) } $ 是否足够大，使得测试样本 $ {\mathbf{x}}_{t}^{\left( k\right) } $ 成为类别 $ i $ 的异常点（第15-24行）。如果测试样本对于所有 $ N $ 个类别都是异常点，那么它被确定为一个漂移样本。否则，我们确定它是一个内分布样本，并且其最近的质心由最近的质心确定（第26行）。MAD的优势在于每个类别都有自己的距离阈值来根据其内类分布确定异常点。例如，如果一个簇更分散，阈值就会更大。

### 解释器

因为很难移动一个漂移样本跨越决策边界，提出了一个专为漂移样本设计的解释器

首先需要设计一个特征扰动机制。大多数现有的扰动方法都是专门为图像设计的，这些图像的特征是数值值。在我们的情况下，$ {\mathbf{x}}_{t} $的特征可以是数值的也可以是分类的，因此直接应用现有的方法将产生不明确的特征值。为了确保扰动对于数值和分类特征都是有意义的，我们提出通过替换特征值来扰动 $ {\mathbf{x}}_{t} $，这个特征值对应于参考训练样本 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 中的特征值。这个 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 是训练样本，它与中心点 $ {\mathbf{c}}_{{y}_{t}} $ 的潜在距离最短。这样一来，我们的解释目标就是识别一组特征，使得用 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 中的特征替换它们，将对 $ f\left( {\mathbf{x}}_{t}\right) $ 和 $ {\mathbf{c}}_{{y}_{t}} $ 之间的距离产生最大的影响
# 全文翻译

杨Limin $ {}^{ * } $, 郭Wenbo $ {}^{ \dagger } $, 郝Qingying $ {}^{ * } $, 西塔迪Arridhana $ {}^{ \ddagger } $

阿赫马兹德Ali Ahmadzadeh $ {}^{ \ddagger } $, 邢Xinyu $ {}^{ \dagger } $, 王Gang $ {}^{ * } $

*伊利诺伊大学香槟分校 $ {}^{ \dagger } $ 宾夕法尼亚州立大学 $ {}^{ \ddagger } $ 蓝色六边形

liminy2@illinois.edu, wzg13@ist.psu.edu, qhao2@illinois.edu, \{arri, ali\}@bluehexagon.ai, xxing@ist.psu.edu, gangw@illinois.edu

摘要

概念漂移对将机器学习模型应用于解决实际安全问题构成了一个关键挑战。由于攻击者（或良性对手）的行为变化，测试数据的分布往往随着时间的推移从原始训练数据中发生变化，导致部署的模型出现重大失败。

为了对抗概念漂移，我们提出了一种名为CADE的全新系统，旨在1) 检测偏离现有类别的变化样本，以及2) 提供解释来解释检测到的漂移。与传统方法（需要大量新标签来统计确定概念漂移）不同，我们的目标是识别随着时间推移到达的单个变化样本。认识到高维异常空间带来的挑战，我们提出将数据样本映射到低维空间，并自动学习一个距离函数来测量样本之间的差异。使用对比学习，我们可以充分利用训练数据集中的标签来学习如何比较和对比样本对。为了解释检测到的漂移的意义，我们开发了一种基于距离的解释方法。我们展示在这种情况中解释“距离”比专注于解释决策边界的传统方法要有效得多。我们在两个案例研究中评估了CADE：Android恶意软件分类和网络入侵检测。我们还与一家安全公司合作，在其恶意软件数据库上测试CADE。我们的结果表明，CADE能够有效地检测变化样本并提供有意义的解释。

## 1 引言

部署基于机器学习的网络安全应用可能会非常困难，因为存在概念漂移。无论是恶意软件分类、入侵检测还是在线滥用检测 $ \left\lbrack {6,{12},{17},{42},{48}}\right\rbrack $，基于学习的模型都是在“封闭世界”假设下工作的，期望测试数据的分布大致与训练数据的分布相匹配。然而，实际情况往往并非如此。随着时间推移，数据分布可能会发生变化，导致模型在新的数据分布上表现不佳。这种现象称为概念漂移，它对模型的性能造成了严重的影响。


Figure 1: 漂移样本检测与解释。

环境中的模型部署通常随时间动态变化。这样的变化可能包括良性玩家的有机行为变化以及攻击者的恶意突变和适应。因此，测试数据分布从原始训练数据转移，这可能导致模型出现严重失败[23]。

为了应对概念漂移，大多数基于学习的模型需要定期重新训练 $ \left\lbrack {{36},{39},{52}}\right\rbrack $。然而，重新训练往往需要标注大量的新样本（成本高昂）。更重要的是，确定何时重新训练模型也相当困难。延后的重新训练可能会使过时的模型容易受到新的攻击。

我们设想对抗概念漂移需要建立一个监控系统来检查流入的数据流与训练数据（以及/或当前的分类器）之间的关系。高层的想法如图1所示。当原始分类器在生产空间中工作时，另一个系统应该定期检查它对流入的数据样本做出决策的资格。一个检测模块（O）可以过滤出那些远离训练空间漂移的样本。更重要的是，为了解释漂移的原因（例如，攻击者的变异、有机行为的变化、之前未知的系统漏洞），我们需要一种解释方法（2）将检测决策与具有语义意义的特征联系起来。这些两种能力对于为开放世界环境准备基于学习的安全应用至关重要。

先前的工作已经探索了通过直接检查原始分类器的预测信心来检测漂移样本的方法（O）[32]。低信心得分可能表明传入的样本是漂移样本。然而，这个信心得分是基于所有类别都已知的假设（封闭世界）计算的概率（总和为1.0）。不属于任何现有类别的漂移样本可能会被错误地分配给一个错误的类别（由现有工作 $ \left\lbrack {{25},{32},{37}}\right\rbrack $ 验证）。最近的一项工作提出了计算新样本与现有类别之间的非一致性度量以确定适应性的想法[38]。这种非一致性度量是基于一个距离函数来量化样本之间的差异。然而，我们发现，尤其是在数据稀疏且维度高的情况下，这样的距离函数很容易失去效力。


请注意，"non-conformity measure" 被翻译为 "非一致性度量"，"distance function" 被翻译为 "距离函数"，"closed-world" 被翻译为 "封闭世界"，"conformity" 被翻译为 "一致性"，"dissimilarity" 被翻译为 "差异"。
我们的方法。在本文中，我们提出了一种新的方法来检测漂移样本，并辅以一种新颖的方法来解释检测决策。我们共同建立了一个名为CADE的系统，即“对比自编码器用于漂移检测和解释”的缩写。关键挑战是导出一个有效的距离函数来测量样本的不相似性。而不是任意选择距离函数，我们利用对比学习[29]的想法从现有的训练数据中学习距离函数，基于现有的标签。给定原始分类器训练数据（多个类别），我们将训练样本映射到一个低维潜空间。映射函数通过对比样本来学习，以增大不同类别样本之间的距离，同时减小同一类别样本之间的距离。我们展示了在潜空间中得到的距离函数能够有效地检测和排名漂移样本。


为了解释漂移样本，我们识别出一组重要的特征，这些特征区分了这个样本与其最近的类别。一个关键的观察是，传统的（监督的）解释方法并不适用于这个情况 $ \left\lbrack {{22},{28},{53},{62}}\right\rbrack $ 。这个见解是，监督解释方法需要两个类别（漂移样本和现有类别）都有足够的样本来估计它们的分布。然而，由于漂移样本位于训练分布之外的空间稀疏区域，这个要求很难满足。相反，我们发现基于距离变化的解释更为有效，即那些导致漂移样本与其最近类别之间的距离发生最大变化的特征。

评测。我们使用两个数据集来评估我们的方法，包括一个Android恶意软件数据集[7]和一个在2018年发布的内存入侵检测数据集[57]。我们的评测显示，我们的漂移检测方法非常准确，平均$ {F}_{1} $分数高于0.96，这优于各种基线和现有方法。我们的分析还展示了使用对比学习减少检测决策模糊性的好处。对于解释模型，我们进行了定量和定性的评估。案例研究也显示，选定的特征与漂移样本的语义行为相匹配。

此外，我们还与安全公司合作者一起，在他们的内部恶意软件数据库上测试了CADE。作为初步测试，我们从395个家族中获得了20,613个Windows PE恶意软件样本，这些样本出现在2019年8月至2020年2月之间。这使我们能够在多样化的环境中测试系统的性能，并与更多的恶意软件家族进行测试。结果令人鼓舞。例如，当在10个家族上进行训练并在160个未见过的家族上进行测试时，CADE实现了$ {F}_{1} $分数为0.95。这导致了对CADE在生产系统中进一步测试和部署的兴趣。

贡献。本文有三项主要贡献。

- 我们提出CADE来补充现有的基于监督学习的网络安全应用，以对抗概念漂移。我们介绍了一种基于对比性表征学习检测漂移样本的有效方法。

- 我们展示了监督式解释方法在解释异常样本时的局限性，并介绍了一种基于距离的解释方法，以应对这种情况。

- 我们广泛地评估了提出的这些方法，并将其应用于两个不同的场景。与一家安全公司的初步测试表明，CADE是有效的。我们已经在[1]中发布了CADE的代码，以支持未来的研究。

## 2 背景与问题范围

在本节中，我们介绍了安全应用背景下的概念漂移，并讨论了一些可能解决方案的局限性。

概念漂移。在许多安全上下文中，监督机器学习已被用于训练检测模型。当部署在实际中时，概念漂移是这些模型面临的主要挑战之一。当测试数据分布偏离原始训练数据时，就会发生概念漂移，导致真实决策边界发生变动[23]。这通常会导致随着时间的推移，原模型出现重大错误。

为了检测概念漂移，研究人员提出了各种技术，这些技术大多涉及收集新的数据集，以统计方式评估模型的行为$ \left\lbrack {9,{10},{20},{31}}\right\rbrack $。对于这些工作中的某些，它们还需要数据标注的努力。在安全应用中，知道存在新的攻击并且收集有关它们的数据首先就是一项挑战。此外，数据标注耗时且需要大量的专业知识。因此，假设大多数传入数据都能得到充分的标注是不切实际的。

除了监督模型，半监督异常检测系统也不一定能够免受概念漂移的影响。例如，大多数网络入侵检测系统都是



除了监督模型，半监督异常检测系统也不一定能够免受概念漂移的影响。例如，大多数网络入侵检测系统都是

---


$ {}^{1} $ https://github.com/whyisyoung/CADE

---


学习了“正常”交通的数据，然后用于检测与学习到的“正常”模式不符的入站交通作为攻击。对于这样的系统，它们可能会检测到以前未知的攻击；然而，概念漂移，尤其是在良性交通中，可能会轻易导致模型失败。本质上，入侵检测仍然是一个分类问题，即区分正常交通和异常交通。其训练仅使用一类数据进行。这在一定程度上削弱了学习成果。这些系统仍然依赖于这样一个假设，即正常数据已经涵盖了所有可能的情况——这在测试阶段经常被违反。


我们的问题范围。我们不是用准备好的全标记数据来检测概念漂移，而是关注一个更实用的场景。如图1所示，我们研究个别样本，以检测那些偏离原始训练数据的样本。这使我们能够在样本到达时检测到漂移样本并标记（一部分）它们。一旦我们积累了足够的漂移样本，我们就可以评估重新训练模型的需要。

在多类分类设置中，存在两种主要类型的概念漂移。类型A：引入新类：漂移样本来自一个新类，该类在训练数据集中不存在。因此，原本训练的分类器无法对漂移样本进行分类；类型B：内部类进化：漂移样本仍然来自现有类，但它们的行为模式与训练数据集中的行为模式有显著差异。在这种情况下，原始分类器在这些漂移样本上很容易出错。

在这篇论文中，我们主要关注类型A概念漂移，即在多类设置中引入一个新的类别。以恶意软件分类为例（图1），我们的目标是检测和解释从现有训练数据中的所有类别未见过的恶意软件家族中出现的漂移样本。本质上，漂移样本是对所有现有类别的训练数据的出界样本。在第六节中，我们探讨了将我们的解决方案适应于解决类型B概念漂移（内部类进化），并检查了我们方法的一般化能力。

可能的解决方案与限制。我们简要讨论了解决这一问题的可能方向以及限制。

第一个方向是使用原始分类器的预测概率。更具体地说，监督分类器通常会输出一个预测概率（或信心）作为预测标签的副产品[32]。例如，在深度神经网络中，softmax函数经常用于产生一个预测概率，该概率表示给定样本属于现有类别的可能性（总和为1）。因此，一个低的预测概率可能表明传入的样本与现有训练数据不同。然而，我们认为预测概率在我们的问题上下文中不太可能有效。原因在于这个概率反映了相对于现有类别的相对适应性（例如，样本更适合于类A而不是类B）。如果样本来自一个全新的类（既不是类A也不是类B），那么预测概率可能会误导人。许多先前的研究[25,32,37]已经表明，来自新类别的测试样本可能导致误导性的概率分配（例如，将一个错误的类与一个高的概率关联起来）。从根本上说，预测概率仍然继承了分类器的“封闭世界假设”，因此不适合检测漂移样本。

与预测概率相比，评估样本与给定类别的直接适应性是一个更有希望的方向。想法是，而不是评估样本是否比其他样本更适合类A或类B，我们评估这个样本在类A中的适应性与其他类A中的训练样本相比如何。例如，可以使用自编码器[33]来根据重建误差评估样本与给定分布的适应性。然而，作为一种无监督方法，当忽略标签时，很难学习训练分布的准确表示（见第4节）。最近的一项工作，Jordaney等人介绍了一个名为Transcend[38]的系统。它将“非一致性度量”定义为适应性评估。Transcend使用可信性$ p $ -值来量化测试样本$ \mathbf{x} $与共享相同类别的训练样本之间的相似性。$ p $是这个类中至少与$ \mathbf{x} $相似或更不相似的其他样本在该类中的比例。虽然这种度量可以定位漂移样本，但这样的系统对“不相似性”的良好定义高度依赖。正如我们在第4节中将展示的那样，任意的不相似性度量（尤其是当数据维度很高时）可能导致性能不佳。

## 3 设计CADE



我们提出一个名为CADE的系统，用于检测和解释漂移样本。我们首先描述我们的设计背后的直觉和洞察，然后是每个组件的技术细节。

## 3.1 我们的设计背后的洞察

如图 1 所示，我们的系统有两个组件：（1）检测偏离训练分布的样本；以及（2）解释这些偏离样本，以帮助分析师理解偏离的含义。经过初步分析，我们发现这两个任务都面临着一个共同的问题：偏离样本位于一个稀疏的异常点空间中，这使得难以推导出对于两个任务都需要的意义重大的距离函数。

首先，检测偏离样本需要学习一个好的距离函数，以衡量“偏离样本”与现有分布的不同。然而，异常点空间是无界的且非常稀疏。对于高维数据，距离的概念由于“维度灾难” [74] 而开始失去效力。其次，解释的目标是识别一小部分最重要的特征，这些特征能够最有效地区分偏离样本与训练数据。因此，我们也需要一个有效距离函数来衡量差异。

在接下来的部分中，我们将设计一个偏离检测模块和一个解释模块，共同解决这些挑战。在高级别上，我们首先使用对比学习来学习训练数据的压缩表示。对比学习的关键好处是，它能够利用现有的标签来达到比无监督方法，如自编码器 [33] 和主成分分析（PCA） [2] 更好的性能。这使我们能够从训练数据中学习一个检测偏离样本的距离函数（第 3.2 节）。对于解释模块，我们将描述一个基于距离的解释公式，以解决上述挑战（第 3.3 节）。

## 3.2 漂移样本检测

漂移检测模型监控传入的数据样本，以检测传入的样本不在训练数据的分布范围内。

对比学习对于潜在表示。我们探讨了对比学习以学习训练数据的良好表示。对比学习利用训练数据中现有的标签来学习一个有效的距离函数来测量不同样本的相似度（或对比度）[16]。与监督分类器不同，对比学习的目标不是将样本分类到已知类别。它的目标是学习如何比较两个样本。

如图2所示，给定输入样本（高维特征向量），对比学习模型旨在将它们映射到一个低维隐空间。该模型被优化，使得在隐空间中，同一类别的样本对之间的距离较小，而不同类别的样本对之间的距离较大。因此，隐空间中的距离度量可以反映样本对之间的差异。任何表现出与所有现有类别有较大距离的新样本都是候选漂移样本。

为了实现这个想法，我们使用了一个带有对比损失的自编码器。自编码器是一个有用的工具，用于学习给定输入分布的压缩表示（具有减少的维度）[33]。形式上，设 $ \mathbf{x} \in {\mathbb{R}}^{q \times 1} $ 是给定训练集的一个样本。我们训练一个包含编码器 $ f $ 和解码器 $ h $ 的自编码器。注意，$ f $ 是由 $ \mathbf{\theta } $ 参数化的；$ h $ 是由 $ \mathbf{\phi } $ 参数化的。我们构造损失函数如下：



最小化 \(\mathbf{\theta },\mathbf{\phi }\) 对于 \(\mathbf{x}\) 的期望 \(\parallel \mathbf{x} - \widehat{\mathbf{x}}{\parallel }_{2}^{2}\) 加上 \(\lambda\) 对 \(\mathbf{x}_{i},\mathbf{x}_{j}\) 的期望 \(\left\lbrack \left( {1 - {y}_{ij}}\right) {d}_{ij}^{2} + {y}_{ij}{\left( m - {d}_{ij}\right) }_{ + }^{2}\right\rbrack\)。

翻译后的文本。

在此，第一个术语是自动编码器的重建损失。更具体地说，编码器$ f $的目标是学习原始输入的良好表征。给定一个输入$ \mathbf{x} $，编码器$ f $将原始输入$ \mathbf{x} $映射到一个低维表征$ \mathbf{z} = f\left( {\mathbf{x};\mathbf{\theta }}\right) $。自动编码器确保了这个潜在


图2：对比学习的高级概念。

表征 $ z $ 可以解码以重建原始输入，且重构损失最小。在这里，$ \widehat{\mathbf{x}} \in {\mathbb{R}}^{q \times 1} $ 是这个原始输入的重构，即，$ \widehat{\mathbf{x}} = h\left( \mathbf{z}\right) $。这个损失项代表了 $ \mathbf{x} $ 和 $ \widehat{\mathbf{x}} $ 之间的均方误差。

第二个方程式（1）项指的是对比损失，它以一对样本 $ \left( {{\mathbf{x}}_{i},{\mathbf{x}}_{j}}\right) $ 和它们的关系 $ {y}_{ij} $ 作为输入。如果两个样本来自不同的类别，则 $ {y}_{ij} = 1 $；如果两个样本来自同一类别，则 $ {y}_{ij} = 0 $。$ {\left( \cdot \right) }_{ + } $ 是对 $ \max \left( {0, \cdot }\right) $ 的简写，而 $ {d}_{ij} $ 是隐空间表征 $ {\mathbf{z}}_{i} = f\left( {{\mathbf{x}}_{i};\mathbf{\theta }}\right) $ 和 $ {\mathbf{z}}_{j} = f\left( {{\mathbf{x}}_{j};\mathbf{\theta }}\right) $ 之间的欧氏距离，其中 $ \mathbf{z} \in {\mathbb{R}}^{d \times 1}\left( {d \ll p}\right) $。这个损失项最小化如果它们来自同一类别，则 $ {\mathbf{x}}_{i} $ 和 $ {\mathbf{x}}_{j} $ 在隐空间中的距离，并最大化它们之间的距离，直到半径 $ m > 0 $ 被定义，这样不相似的配对只在其距离在这个半径内时才对损失函数做出贡献。$ \lambda $ 是损失函数中第二个项的超参数。

在对比学习之后，编码器 $ f $ 可以将输入样本映射到一个低维的隐空间中，其中每个类形成紧密的群体（如图2所示）。在这个隐空间中，距离函数可以有效地识别新样本从这些群体中漂移开的情况。

基于MAD的漂移样本检测。在训练对比自编码器之后，我们可以使用它来检测漂移样本。给定一组测试样本 $ K $ $ \left\{ {\mathbf{x}}_{t}^{\left( k\right) }\right\} (k = $ $ 1,\ldots, K) $，我们寻求确定每个样本 $ {\mathbf{x}}_{t}^{\left( k\right) } $是否相对于训练数据中的现有类别是漂移样本。检测方法如算法1所示。

假设训练集有 $ N $ 个类别，每个类别有 $ {n}_{i} $ 个训练样本，对于 $ i = 1,2,\ldots, N $ 。我们首先使用编码器将所有训练样本映射到隐空间中（第2-4行）。对于每个类别 $ i $，我们计算其质心 $ {\mathbf{c}}_{i} $（通过在欧几里得空间中取每个维度的平均值，第5行）。给定一个测试样本 $ {\mathbf{x}}_{t}^{\left( k\right) } $，我们也使用编码器将其映射到隐空间表示 $ {\mathbf{z}}_{t}^{\left( k\right) } $（第14行）。然后，我们计算测试样本与其质心之间的欧氏距离：$ {d}_{i}^{\left( k\right) } = {\begin{Vmatrix}{\mathbf{z}}_{t}^{\left( k\right) } - {\mathbf{c}}_{i}\end{Vmatrix}}_{2} $（第16行）。根据其到质心的距离，我们确定这个测试样本是否对于 $ N $ 个类别中的每一个都是分布外的。在这里，我们根据样本到质心的距离而不是样本到最近训练样本的距离做出决策。这是因为后一种选择很容易受到训练数据中的异常点的影响。

---


算法1：对比性自编码器驱动检测。

训练数据 $ {\mathbf{x}}_{i}^{\left( j\right) }, i = 1,\ldots, N, j = 1,\ldots ,{n}_{i}, N $ 表示类别数量，$ {n}_{i} $ 表示类别 $ i $ 下的训练样本数量；测试数据 $ {\mathbf{x}}_{t}^{\left( k\right) } $，$ t $ 指测试集，$ k = 1,\ldots, K, K $ 是总测试样本数量；编码器 $ f $；常数 $ b $。

输出: 每个测试样本的漂移分数 $ {A}^{\left( k\right) } $，最接近的类别 $ {y}_{t}^{\left( k\right) } $，每个类别的中心 $ {\mathbf{c}}_{i},{\mathrm{{MAD}}}_{i} $ 到每个类别。

对于班级$ i = 1 $到$ N $做

对于 $ j = 1 $ 到 $ {n}_{i} $ 做

$ {\mathbf{z}}_{i}^{\left( j\right) } = f\left( {{\mathbf{x}}_{i}^{\left( j\right) };\mathbf{\theta }}\right) \; \vartriangleright $ 第 $ j $ 层的 $ i $ 号样本的隐特征表示。

$ {\mathbf{c}}_{i} = \frac{1}{{n}_{i}}\mathop{\sum }\limits_{{j = 1}}^{{n}_{i}}{\mathbf{z}}_{i}^{\left( j\right) }\; \vartriangleright $ 第 $ i $ 类的中心点。

$ {d}_{i}^{\left( j\right) } = {\begin{Vmatrix}{\mathbf{z}}_{i}^{\left( j\right) } - {\mathbf{c}}_{i}\end{Vmatrix}}_{2} \vartriangleright $ 样本与质心的距离。

结束循环

$ {{\widetilde{d}}_{i} = \operatorname{median}\left( {d}_{i}^{\left( j\right) }\right), j = 1,\ldots ,{n}_{i} } $

$ {\operatorname{MAD}}_{i} = b * \operatorname{median}\left( \left| {{d}_{i}^{\left( j\right) } - {\widetilde{d}}_{i}}\right| \right), j = 1,\ldots ,{n}_{i} $

结束循环

: 对于 $ k = 1 $ 到 $ K $ 做

$ {{\bf z}}_t^{(k)} = f\left( {{\bf x}_t^{(k)}; \mathbf{\theta} }\right) $

对于班级$ i = 1 $到$ N $做

$ {d}_{i}^{\left( k\right) } = {\begin{Vmatrix}{\mathbf{z}}_{t}^{\left( k\right) } - {\mathbf{c}}_{i}\end{Vmatrix}}_{2} $

$ {A}_{i}^{\left( k\right) } = \frac{\left| {d}_{i}^{\left( k\right) } - {\widetilde{d}}_{i}\right| }{{\mathrm{{MAD}}}_{i}} $

结束循环

$ {A}^{\left( k\right) } = \min \left( {A}_{i}^{\left( k\right) }\right), i = 1,\ldots, N $

如果 $ {A}^{\left( k\right) } > {T}_{\mathrm{{MAD}}} $ 则 $ \; \vartriangleright {T}_{\mathrm{{MAD}}} $ 被设置为3.5，这是基于经验[40]。

$ {\mathbf{x}}_{t}^{\left( k\right) } $ 是一个潜在的漂移样本。

否则。

$ {\mathbf{x}}_{t}^{\left( k\right) } $ 是一个不漂移的样本。

结束 if 判断。

最近的类对于 $ {\mathbf{x}}_{t}^{\left( k\right) } $ 。

结束循环

---


为了根据 $ {d}_{i}^{\left( k\right) } $ 确定异常点，挑战在于不同类别的紧密度可能不同，因此需要不同的距离阈值。而不是手动为每个类别设置绝对距离阈值，我们使用了一种称为中位数绝对偏差（MAD）[40]的方法。想法是通过计算 $ {\mathrm{{MAD}}}_{i} $（第6-10行）来估计每个类别的数据分布 $ i $，它是中位数距离 $ {d}_{i}^{\left( j\right) }\left( {j = 1,\ldots ,{n}_{i}}\right) $ 的绝对偏差。在这里 $ {d}_{i}^{\left( j\right) } $ 表示类别 $ i $ 中每个样本与其质心的潜在距离，以及 $ {n}_{i} $ 是类别 $ i $ 中样本的数量（第7行）。然后基于 $ {\mathrm{{MAD}}}_{i} $，我们可以确定 $ {d}_{i}^{\left( k\right) } $ 是否足够大，使得测试样本 $ {\mathbf{x}}_{t}^{\left( k\right) } $ 成为类别 $ i $ 的异常点（第15-24行）。如果测试样本对于所有 $ N $ 个类别都是异常点，那么它被确定为一个漂移样本。否则，我们确定它是一个内分布样本，并且其最近的质心由最近的质心确定（第26行）。MAD的优势在于每个类别都有自己的距离阈值来根据其内类分布确定异常点。例如，如果一个簇更分散，阈值就会更大。


图 3：在我们的设置中，边界基于解释和距离基于解释的说明。

请注意，当一个类别的样本不足时，MAD可能会受到影响，因为它的中位数可能会变得不准确。在我们的设计中，对比学习可以帮助缓解这个问题，因为每个类别都被映射到一个紧凑的区域中，这有助于稳定中位数。

排名漂移样本。如图1所示，漂移样本可能需要分析师进一步调查以解释漂移的含义。鉴于分析师的时间有限，对漂移样本进行排名至关重要，以便分析师可以专注于调查最新颖的变体。我们使用一种简单的方法根据它们与最近邻中心的距离（在行26中计算）对漂移样本进行排名。这允许我们优先调查与最近邻中心最远的漂移样本。

## 3.3 解释漂移样本

解释模块旨在识别导致测试样本远离现有类别的最重要特征。具体来说，给定一个漂移样本 $ {\mathbf{x}}_{t} $，以及它在训练集中的最近类别 $ {y}_{t} $，我们希望识别出一小组特征，使 $ {\mathbf{x}}_{t} $ 成为类别 $ {y}_{t} $ 的异常点。为了实现这一目标，一种直觉反应是将它转化为解释监督学习模型的一个问题，这是一个研究广泛的问题。例如，我们可以将我们的漂移检测器（O）近似为一个分类器，并使用为分类器 $ \lbrack {28},{35} $ , $ {53},{58},{62}\rbrack $ 开发的存在解释方法来推导解释。然而，由于异常点空间的极高稀疏性，我们发现很难移动一个漂移样本跨越决策边界，因此无法推导出有意义的解释。受此启发，我们设计了一种专门为漂移检测设计的新的解释方法，该方法解释漂移样本与其同类样本之间的距离，而不是决策边界。下面，我们先分析“直截了当的方法”，然后描述我们的方法。

基准方法：边界基于解释。鉴于解释监督分类器的丰富文献，一种直观的方法是将漂移检测模块转换为监督学习模型，然后运行现有的解释算法。监督解释方法是为了解释两个类之间的决策边界（例如，类A和类B）。目标是识别${\mathbf{x}}_{t}$内的一个最小特征集，使得扰动这些特征会让${\mathbf{x}}_{t}$跨越决策边界。如图3所示，类A代表来自$ {y}_{t} $的训练样本，类B代表测试集中的检测到的漂移样本。决策边界用蓝色虚线表示（决策边界以距离阈值的形式表示）。给定一个漂移样本${\mathbf{x}}_{t}$（如图3中的星号表示），解释方法通过扰动一组重要特征将样本拉入正域类（即带有灰色画布的区域）。$ {}^{2} $我们使用现有的基于扰动的监督解释方法（文献[13]、[18]、[21]、[22]）实现了这个想法（附录A中的实现细节）。

评估结果如第5节所述，表明这种方法从根本上受到了限制。我们认为原因有二。首先，由于漂移样本的数量有限，很难为决策边界得出一个准确的近似模型。其次，更为重要的是，异常点空间远大于分布内区域。由于漂移样本远离决策边界，很难找到一组特征扰动，将漂移样本带过决策边界进入分布内区域。如果没有越过边界的能力，解释方法将无法获得必要的梯度（或反馈）来计算特征重要性。

我们的方法：基于距离的解释。受到这一观察的启发，我们提出了一种新的方法，该方法通过解释距离（如图3中的红色箭头所示）来识别重要的特征。与基于决策边界做出决策的监督分类器不同，漂移检测模型基于样本到中心点的距离做出决策。因此，我们的目标是找到一组原始特征，帮助漂移样本 $ {\mathbf{x}}_{t} $ 向最近的中心点 $ {\mathbf{c}}_{{y}_{t}} $ 移动。有了这种设计，我们就不再需要强迫 $ {\mathbf{x}}_{t} $ 跨越边界，这很难实现。相反，我们扰动原始特征并观察隐空间中的距离变化。

为了实现这个想法，我们首先需要设计一个特征扰动机制。大多数现有的扰动方法都是专门为图像设计的[18]，这些图像的特征是数值值。在我们的情况下，$ {\mathbf{x}}_{t} $的特征可以是数值的也可以是分类的，因此直接应用现有的方法将产生不明确的特征值。为了确保扰动对于数值和分类特征都是有意义的，我们提出通过替换特征值来扰动 $ {\mathbf{x}}_{t} $，这个特征值对应于参考训练样本 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 中的特征值。这个 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 是训练样本，它与中心点 $ {\mathbf{c}}_{{y}_{t}} $ 的潜在距离最短。这样一来，我们的解释目标就是识别一组特征，使得用 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 中的特征替换它们，将对 $ f\left( {\mathbf{x}}_{t}\right) $ 和 $ {\mathbf{c}}_{{y}_{t}} $ 之间的距离产生最大的影响。替换

$ {}^{2} $ 请注意，我们不在隐空间中执行特征扰动，因为隐特征不携带语义含义。相反，我们在原始输入空间中选择特征。与 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 的特征值也帮助确保扰动样本朝着中心点的粗略方向移动。与之前一样，扰动在原始特征空间中进行，其中特征具有语义含义。

我们使用一个 $ \mathbf{m} \in {\mathbb{R}}^{q \times 1} $ 来表示重要特征，其中 $ {\mathbf{m}}_{i} = 1 $ 表示 $ {\left( {\mathbf{x}}_{t}\right) }_{i} $ 被 $ {\left( {\mathbf{x}}_{{y}_{t}}^{\left( c\right) }\right) }_{i} $ 的值所替换，而 $ {\mathbf{m}}_{i} = 0 $ 表示我们保持 $ {\left( {\mathbf{x}}_{t}\right) }_{i} $ 的值不变。换句话说，$ {\mathbf{m}}_{i} = 1 $ 表示第 $ i $ 个特征被选为重要特征。这个特征掩码的每个元素 $ {\mathbf{m}}_{i} $ 可以从一个伯努利分布中采样，其概率为 $ {p}_{i} $。因此，我们可以保证 $ {\mathbf{m}}_{i} $ 等于 1 或 0。然后，我们的目标就转化为求解 $ {p}_{i} $，其中 $ i = 1,2,\ldots, q $。技术上，这可以通过对 $ {p}_{1 : q} $ 最小化以下目标函数来实现。

期望方差加正则化损失函数：
$$
{\mathbb{E}}_{\mathbf{m} \sim Q\left( \mathbf{p}\right) }{\begin{Vmatrix}{\widehat{\mathbf{z}}}_{t} - {\mathbf{c}}_{{y}_{t}}\end{Vmatrix}}_{2} + {\lambda }_{1}R\left( {\mathbf{m},\mathbf{b}}\right) ,
$$

$$
{\widehat{\mathbf{z}}}_{t} = f\left( {{\mathbf{x}}_{t} \odot \left( {1 - \mathbf{m} \odot \mathbf{b}}\right) + {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } \odot \left( {\mathbf{m} \odot \mathbf{b}}\right) }\right) ,
$$


翻译文本。

$$
R\left( {\mathbf{m},\mathbf{b}}\right) = \parallel \mathbf{m} \odot \mathbf{b}{\parallel }_{1} + \parallel \mathbf{m} \odot \mathbf{b}{\parallel }_{2},\;Q\left( \mathbf{p}\right) = \mathop{\prod }\limits_{{i = 1}}^{q}p\left( {{\mathbf{m}}_{i} \mid {p}_{i}}\right) .
$$


请注意，$ \odot $ 表示逐元素乘法；$ {\widehat{\mathbf{z}}}_{t} $ 表示扰动样本的潜在向量。根据上述方程，直接计算 $ \mathbf{m} $ 很困难，因为其维度很高。为了加快搜索速度，我们引入了一个过滤器 $ \mathbf{b} $ 来预先过滤掉不值得考虑的特征。我们设定 $ {\left( \mathbf{b}\right) }_{i} = 0 $，如果 $ {\left( {\mathbf{x}}_{t}\right) }_{i} $ 和 $ {\left( {\mathbf{x}}_{{y}_{t}}^{\left( c\right) }\right) }_{i} $ 是相同的。换句话说，如果 $ {\mathbf{x}}_{t} $ 的特征值与参考样本 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 的特征值相同，那么这个特征在优化过程中被排除（因为它不会影响距离的变化）。这样，$ {\widehat{\mathbf{z}}}_{t} = f\left( {{\mathbf{x}}_{t} \odot \left( {1 - \mathbf{m} \odot \mathbf{b}}\right) + {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } \odot \left( {\mathbf{m} \odot \mathbf{b}}\right) }\right) $ 表示扰动样本的潜在向量。

在方程（2）中，损失函数中的第一个项旨在最小化扰动样本 $ {\widehat{\mathbf{z}}}_{t} $ 与类别 $ {y}_{t} $ 的中心 $ {\mathbf{c}}_{{y}_{t}} $ 的潜空间距离。$ \mathbf{m} $ 中的每个元素是从参数为 $ {p}_{i} $ 的伯努利分布中采样的。在这里，我们使用 $ Q\left( \mathbf{p}\right) $ 来代表它们的联合分布。$ {}^{3} $ 对于第二个项，$ \lambda $ 是一个超参数，控制弹性网正则化 $ R\left( \cdot \right) $ 的强度，它限制了 $ \mathbf{m} $ 中非零元素的数量。通过最小化 $ R\left( {\mathbf{m},\mathbf{b}}\right) $，优化过程选择了一个最小的重要特征子集。

请注意，伯努利分布是离散的，这意味着相对于 $ {p}_{i} $ 的 $ {\mathbf{m}}_{i} $ 的梯度（即 $ \frac{\partial {\mathbf{m}}_{i}}{\partial {p}_{i}} $ ）没有明确的定义。我们不能通过梯度优化方法来解决式（2）中的优化问题。为了解决这个挑战，我们引用了[45]中的变量变换技巧。通过用连续近似（即实数分布）替换伯努利分布，该分布由 $ {p}_{i} $ 参数化，我们使梯度计算成为可能。然后，我们可以通过梯度优化方法（本文中我们使用Adam优化器）来解决参数 $ {p}_{1 : q} $ 。

我们假设每个特征是从一个不同的伯努利分布中独立抽取的。

<table><thead><tr><th></th><th>Id</th><th>Family</th><th># of Samples</th></tr></thead><tr><td></td><td>0</td><td>FakeInstaller</td><td>925</td></tr><tr><td></td><td>1</td><td>DroidKungFu</td><td>667</td></tr><tr><td></td><td>2</td><td>Plankton</td><td>625</td></tr><tr><td></td><td>3</td><td>GingerMaster</td><td>339</td></tr><tr><td></td><td>4</td><td>BaseBridge</td><td>330</td></tr><tr><td></td><td>5</td><td>Iconosys</td><td>152</td></tr><tr><td></td><td>6</td><td>Kmin</td><td>147</td></tr><tr><td></td><td>7</td><td>FakeDoc</td><td>132</td></tr><tr><td colspan="4">Total:3,317</td></tr></table>


表 1：Drebin 数据集中的 Android 恶意软件样本。

## 4 评估：漂移检测

在本节中，我们使用两个安全应用程序来评估我们的系统：Android恶意软件家族归属，以及网络入侵检测。在本节（第4节）中，我们专注于漂移检测模块的评估。我们将在第5节中评估解释模块。在这些受控实验之后，我们在安全公司的恶意软件数据库上测试了我们的系统（第7节）。

## 4.1 实验设置和数据集

Android恶意软件归属。我们使用Drebin数据集[7]来探索恶意软件家族归属问题。原始分类器（图1中的$ \mathbf{O} $模块）是一个多层感知机（MLP）分类器。它识别一个恶意软件样本属于哪个家族。Drebin数据集包含5,560个Android恶意软件样本。对于这次评估，我们选择了8个家族$ {}^{4} $，每个家族至少有100个恶意软件样本（总共3,317个样本，见表1）。

为了评估漂移样本检测模块，对于每项实验，我们选择8个家族中的一个作为未知的家族。例如，假设我们选择了“FakeDoc”（第7家族）作为未知家族。我们将其他七个家族分成训练集和测试集，并将“FakeDoc”仅添加到测试集。这样，在训练期间“FakeDoc”是不可用的。我们的目标是正确地识别测试时间来自“FakeDoc”的样本作为漂移样本。

我们将训练集和测试集的比例分为80:20。分割基于时间戳（恶意软件创建时间），这是多项工作[52,65]推荐的做法，以模拟一个现实的环境。基于时间的分割也意味着我们不能在训练模型时使用仅出现在测试集中的新特征。这使我们只剩下7,218个特征。然后，我们使用scikit-learn的VarianceThreshold函数[51]来移除方差非常低的特征（即，$ < {0.003} $），这创造了最终的1,340个特征集。

<table><thead><tr><th>Id</th><th>Family</th><th># of Flows</th></tr></thead><tr><td>0</td><td>Benign</td><td>66,245</td></tr><tr><td>1</td><td>SSH-Bruteforce</td><td>11,732</td></tr><tr><td>2</td><td>DoS-Hulk</td><td>43,487</td></tr><tr><td>3</td><td>Infiltration</td><td>9,238</td></tr><tr><td colspan="3">Total:130,702</td></tr></table>


表 2：网络入侵数据集：来自 IDS2018 数据集的 3 个网络入侵类别和一个良性类别。

为了展示结果的泛化能力，我们迭代地选择每个恶意软件家族作为“未见家族”并重复实验。

网络入侵检测。我们使用一个网络入侵数据集[57]，我们将其称为IDS2018。该数据集包含不同类型的网络轨迹，这些轨迹是由已知攻击生成的。为了我们的评估，我们选择良性类别（一天的流量）和三种不同的攻击类别：SSH-Bruteforce、Dos-Hulk和Infiltration。SSH-Bruteforce是一种暴力攻击，用于猜测SSH登录密码。DoS-Hulk攻击旨在向目标机器发送多余的请求，试图使机器暂时不可用。Infiltration攻击首先发送带有恶意附件的电子邮件，利用主机应用程序的漏洞，然后利用后门运行端口扫描，以发现更多的漏洞。我们对感兴趣的读者[57]提供了更多关于攻击的详细信息。为了加快实验并测试不同的设置，我们使用了其流量的$ {10}\% $作为实验数据集（表2）。在附录D中，我们展示了更多的流量只会增加计算开销，并且对所选方法的性能几乎没有影响。

我们迭代地选择攻击家族中的一个作为未见过的家族，并在测试集中只包含这个家族。我们重复实验以报告平均性能。我们将训练-测试集的比例分为80:20。请注意，IDS2018数据集中的特征需要进一步归一化和编码。为了现实性，我们只使用训练数据来构建特征编码方案。在较高层次上，每个样本代表一个网络流量。诸如“目的地端口”和“网络协议”的分类特征使用独热编码进行编码。其他77个统计特征被归一化到0和1之间，使用一个MinMaxS-caler。每个网络流量有83个特征。我们发布的代码的详细特征工程步骤可在文档中找到。

评估指标。对于漂移检测模块（图1中的模块 $ \mathbf{O} $），正样本是测试集中的未见家族样本。负样本是已知家族的其余测试样本。给定一个检测样本的排名列表，我们模拟分析师从列表的顶部检查样本。随着我们从列表的顶部向下移动，我们计算三种评估指标：精确度、召回率和 $ {F}_{1} $ 分数。精确度衡量真阳性与所有预测阳性的比率。召回率衡量真阳性与所有实际阳性样本的比例。 $ {F}_{1} $ 分数是一个精确度和召回率的调和平均值，用于衡量检测性能。

---


$ {}^{4} $ 两个家族 FakeInstaller 和 Opfake 在攻击的本质方面非常相似。在它们的家族标签方面存在强烈的分歧，即样本在某些引擎中被标记为一种家族，而在其他引擎中被标记为另一种家族。因此，我们只包括了 FakeInstaller（表 1）。

---


translated text.


超出

图 4：精确度和召回率与检查样本的数量（根据各自方法对漂移样本进行排名）。

<table><thead><tr><th rowspan="2">方法</th><th colspan="4">Drebin $ \left( {\mathrm{{Avg}} \pm \mathrm{{Std}}}\right) $</th><th colspan="4">IDS2018 (Avg $ \pm $ Std)</th></tr><tr><th>精确度</th><th>召回率</th><th>$ {F}_{1} $</th><th>正常努力</th><th>精确度</th><th>召回率</th><th>$ {F}_{1} $</th><th>正常努力</th></tr></thead><tr><td>原版AE</td><td>$ {0.63} \pm {0.17} $</td><td>$ {0.88} \pm {0.13} $</td><td>$ {0.72} \pm {0.15} $</td><td>$ {1.48} \pm {0.31} $</td><td>$ {0.61} \pm {0.16} $</td><td>$ {0.99} \pm {0.00} $</td><td>$ {0.74} \pm {0.12} $</td><td>$ {1.74} \pm {0.40} $</td></tr><tr><td>超越</td><td>$ {0.76} \pm {0.19} $</td><td>$ {0.90} \pm {0.14} $</td><td>$ {0.80} \pm {0.12} $</td><td>$ {1.29} \pm {0.45} $</td><td>$ {0.64} \pm {0.45} $</td><td>$ {0.67} \pm {0.47} $</td><td>$ {0.65} \pm {0.46} $</td><td>$ {1.45} \pm {0.57} $</td></tr><tr><td>CADE</td><td>$ {0.96} \pm {0.05} $</td><td>$ {0.96} \pm {0.04} $</td><td>$ {0.96} \pm {0.03} $</td><td>$ {1.00} \pm {0.09} $</td><td>$ {0.98} \pm {0.02} $</td><td>$ {0.93} \pm {0.09} $</td><td>$ {0.96} \pm {0.06} $</td><td>$ {0.95} \pm {0.07} $</td></tr></table>

表 3：Drebin 和 IDS2018 数据集上的漂移检测结果。我们比较了 CADE 与两种基线 Transcend [38] 和 Vanilla AE。对于每个评估指标，我们都报告了所有设置下的平均值和标准差。


图5：$ {F}_{1} $ 评分漂移图6：归一化调查-检测。

未见家族样本中的样本。召回率衡量检测模块成功发现的所有未见家族样本的比例。$ {F}_{1} $分数是精确度和召回率的调和平均值：$ {F}_{1} = 2 \times \frac{\text{ 精确度 } \times \text{ 召回率 }}{\text{ 精确度 } + \text{ 召回率 }} $ 。最后，为了量化检查的努力，我们定义了一个称为检查努力度量的指标，它是检查的总样本数，除以测试集中真实未见家族样本的数量。

基准方法。我们包括两种主要的基础线。第一个基础线是一个标准的Vanilla自编码器[33]，它用于说明对比学习的好处。我们将Vanilla自编码器（AE）设置为与CADE相同的层数和输出维数。我们使用它来进行维度降低，将输入映射到一个潜空间中，在那里我们使用相同的MAD方法来检测和排名漂移样本。这个基线的差异与CADE不同，因为该基线不进行对比学习。超参数设置见附录B。

第二个基线是Transcend [38]。如第2节所述，Transcend定义了一个“非一致性度量”来量化输入样本与预测类之间的吻合程度，并计算一个可信度 $ p $ -值来确定输入样本是否为漂移样本。我们从作者那里获得了Transcend的源代码，并遵循论文中的描述，对实现进行了调整，以支持多类分类（原始代码只支持二元分类）。具体来说，我们使用 $ - p $ 初始化非一致性度量，其中 $ p $ 是softmax输出概率，表示测试样本属于给定家族的概率。然后我们计算测试样本的可信度 $ p $ -值。如果对于所有现有家族，$ p $ -值接近零，我们将其视为漂移样本。我们根据最大可信度 $ p $ -值对漂移样本进行排名。请注意，我们没有使用其他异常检测方法 $ \left\lbrack {{14},{41},{49}}\right\rbrack $ 作为我们的基线，主要是因为它们的工作设置与CADE和Transcend不同。更具体地说，这些方法在训练过程中需要一个辅助的异常数据集，或者需要修改原始分类器。对于生产环境中的恶意软件分类器，这些要求很难满足（第9节中有更详细的讨论）。

## 4.2 评估结果

在本节中，我们首先比较了 CADE 的漂移检测性能与基线，并评估了对比学习的影响。然后，我们进行案例研究，以调查检测错误的原因。

漂移样本检测性能。首先，我们使用一个实验设置来解释我们的评估过程。以Drebin数据集为例。假设我们在测试集中使用家庭Iconosys作为未见过的家庭。在训练检测模型（没有任何Iconosys样本）之后，我们使用它来检测并排名漂移样本。为了评估排名列表的质量，我们模拟分析师从列表顶部检查样本。

图4a显示，随着我们检查更多的漂移样本（最多150个样本），精度保持在很高的水平（超过0.97），而召回率逐渐达到$ {100}\% $。结合


图 8：Drebin 数据集中的测试样本与其原始空间和隐空间中最近聚类中心的距离的箱形图。来自先前未见家族的样本被视为漂移样本。

准确性和召回率的最高 $ {F}_{1} $ 分数为0.98。在150个样本之后，精度会下降，因为剩余的集合中不再有未见过的家庭样本。这确认了排名列表的高质量，这意味着几乎所有未见过的家庭样本都排在最前面。

作为比较，Transcend和Vanilla $ \mathrm{{AE}} $的排名列表不那么令人满意。对于Transcend（图4b），前150个样本的精度召回都很低，这表明前排的样本不是来自未见过的家族。在检查了150个样本后，我们开始看到更多的来自未见过的家族的样本。在检查了350个样本后，Transcend已经覆盖了大部分来自未见过的家族的样本（即召回率接近1.0），但精度只有0.46。这意味着分析师检查的样本中有一半是不相关的。最佳 $ {F}_{1} $ 分数为0.63。如图 $ 4\mathrm{c} $ 所示，Vanilla $ \mathrm{{AE}} $的表现更差。即使在检查了600个样本后，召回率也只有略高于0.8。

为了概括观察结果，我们迭代地对待每个家族作为未见的家族，并计算不同设置下的平均统计数据，以获得 $ {F}_{1} $ 分数（见图5）和归一化的检查努力（见图6）。表3进一步展示了相应的精确度和召回率。对于每种实验设置，我们报告了每个模型的最高 $ {F}_{1} $ 分数。这个 $ {F}_{1} $ 分数是在分析家沿着排名列表向下移动并停止检查时实现的，当他们开始获得大量误报时。“检查努力”是指达到报告的 $ {F}_{1} $ 分数的总检查样本数，该数被测试集中的真实漂移样本数归一化。

表3确认了CADE能够准确地检测漂移样本，并且超过了两个基线。在Drebin上，CADE的平均$ {F}_{1} $分数为0.96，而基线的$ {F}_{1} $分数分别为0.80和0.72。对于IDS2018数据集，也能得出类似的结论。此外，CADE的标准差远小于基线的标准差，表明在不同实验设置中性能更加一致。最后，我们展示了CADE具有较低的归一化检查努力，这证实了排名的高质量。

请注意，Transcend基线在实际应用中某些情况下表现良好。例如，当DoS-Hulk设置为IDS2018数据集中未见过的家族时，其$ {F}_{1} $分数为$ {99.69}\% $（与我们系统的性能相似）。然而，问题在于Transcend的性能在不同设置中不够稳定，这在表3中的高标准偏差中得到了反映。

对比学习的影响。为了理解性能提升的来源，我们考察了对比学习的效应。首先，我们展示了一个可视化图，如图7所示，该图显示了Drebin数据集的训练样本和来自选定的未知家族（FakeDoc）的测试样本的t-SNE图。t-SNE [66]执行其自身的非线性降维，将数据样本投影到一个二维图中。为了可视化我们的数据样本，我们将样本从原始空间 $ \left( {1,{340}\text{维度}}\right) $ 映射到一个二维空间（图7a）。我们也将样本从隐空间（7维度）映射到二维空间进行比较（图 $ 7\mathrm{\;b} $ 和图 $ 7\mathrm{c} $ ）。我们可以观察到，CADE的隐空间中的样本形成了更紧凑的簇，使得更容易将现有样本与未知家族区分开来。

为了提供不同实验设置下的统计视角，我们绘制了图8。与之前一样，我们迭代地选取一个家族作为Drebin中的不可见家族。然后我们在原始特征空间（图8a）和CADE生成的隐空间（图8b）中测量测试样本与其最近聚类中心的距离。IDS2018数据集的结果具有相同的结论，因此为了简洁省略了它们。我们展示了在原始空间中漂移样本和非漂移样本更难以分离。在对比学习之后，隐空间中的分离更为明显。原因在于对比学习已经学习了适合的距离函数，该函数可以进一步拉伸不同类别的样本，使得更容易检测到不可见家族。

案例研究：CADE的局限性。CADE在大多数设置中表现良好。然而，我们发现，在某些情况下，CADE的性能不佳。例如，当使用Fake-Installer作为未知的家族时，我们的检测精度仅为$ {82}\% $，而召回率达到$ {100}\% $。我们注意到，许多来自GingerMaster和Plankton家族的测试样本被检测为漂移样本。经过更仔细的检查，我们发现，当FakeInstaller被视为未知家族时，为了保持整体80:20的训练-测试比例，我们需要在GingerMaster和Plankton家族的训练样本数量还不足时分割数据集。因此，许多来自GingerMaster和Plankton家族的测试样本在外观上与这两个家族的小数量训练样本（基于潜在距离）有很大差异。外部证据也表明，这两个家族有许多变体$ \left\lbrack {5,{70}}\right\rbrack $。虽然这些恶意软件变体不是来自新的家族（在我们的定义下为假阳性），但它们也可能对理解同一家族内的恶意软件变异有价值。

## 5 评估：解释漂移样本

为了评估解释模块，我们从每个数据集（即 Drebin 的 FakeDoc 和 IDS2018 的 Infiltration）中随机选择一个家族作为漂移样本。其他设置的结果具有相同的结论，因此为了简洁，省略了这些结果。基于这种设置，我们对检测到的漂移样本生成解释，并对解释结果进行定量和定性的评估。

<table><thead><tr><th>方法</th><th>Drebin-FakeDoc 平均 $ \pm $ 标准差</th><th>IDS2018-Infiltration 平均 $ \pm $ 标准差</th></tr></thead><tr><td>原始距离</td><td>5.363 $ \pm $ 0.568</td><td>$ {11.715} \pm {2.321} $</td></tr><tr><td>随机</td><td>5.422 $ \pm $ 1.773</td><td>$ {11.546} \pm {3.169} $</td></tr><tr><td>边界基于</td><td>$ {3.960} \pm {2.963} $</td><td>$ {6.184} \pm {3.359} $</td></tr><tr><td>COIN [43]</td><td>$ {6.219} \pm {3.962} $</td><td>$ {8.921} \pm {2.234} $</td></tr><tr><td>CADE</td><td>0.065 $ \pm $ 0.035</td><td>2.349 $ \pm $ 3.238</td></tr></table>

表 4：基于与最近聚类中心距离的平均值比较解释的精确度。较短的距离更好。“原始距离”是漂移样本与最近聚类中心的距离。

## 5.1 实验设置

基线方法。我们考虑三种基线方法：（1）随机基线，它随机选择特征作为重要特征；(2) 第3节描述的基于边界的解释方法，以及（3）一种称为COIN[43]的无监督解释方法。由于空间限制，我们只简要描述COIN的工作原理。COIN构建一组局部线性SVM分类器来区分单个异常点与其分布邻域样本。由于线性SVM分类器是自解释的，它们可以 pinpoint重要特征，这些特征有助于异常点的分类。为了公平比较，我们选择与我们的方法相同数量的顶级特征。这些基线的实现和超参数可以在附录B中找到。请注意，我们没有选择现有的黑盒解释方法（例如，LIME[53]和SHAP[44]）作为我们的比较基线。这是因为由于它们能够访问原始模型，白盒方法通常比黑盒方法表现更好[67]。

评估指标。定量地，我们直接评估所选特征对距离变化的影响。给定一个测试样本 $ {\mathbf{x}}_{t} $ 和一种解释方法，我们获得所选特征 $ {\mathbf{m}}_{t} $，其中 $ {\left( {\mathbf{m}}_{t}\right) }_{i} = 1 $，如果第 $ {i}^{\text{th }} $ 个特征被选为重要，我们通过这个指标量化这个解释结果的准确性：$ {d}_{{\mathbf{x}}_{t}}^{\prime } = \parallel f\left( {{\mathbf{x}}_{t} \odot \left( {1 - {\mathbf{m}}_{t}}\right) + {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } \odot } \right. $ $ \left. {\mathbf{m}}_{t}\right) - {\mathbf{c}}_{{y}_{t}}{\parallel }_{2} $，其中 $ f,{\mathbf{c}}_{{y}_{t}} $ 和 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $ 在Eqn. (2)中的定义与 ones 相同。$ {d}_{{\mathbf{x}}_{t}}^{\prime } $ 表示 $ {\mathbf{x}}_{t} $ 扰动样本与其最近邻中心点 $ {\mathbf{c}}_{{y}_{t}} $ 之间的潜在距离。扰动样本是通过将 $ {\mathbf{x}}_{t} $ 中的重要特征值替换为类 $ {y}_{t} $ 最接近中心点（即 $ {\mathbf{x}}_{{y}_{t}}^{\left( c\right) } $）的训练样本的特征值而产生的。如果所选特征确实重要，那么将它们替换为类 $ {y}_{t} $ 训练样本的特征值将减少扰动样本与 $ {\mathbf{c}}_{{y}_{t}} $ 中心点的距离。在这种情况下，较低的距离 $ {d}_{{\mathbf{x}}_{t}}^{\prime } $ 更好。

除了这个 $ {d}_{{x}_{t}}^{\prime } $ 度量之外，我们还在第 5.2 节中使用了一个传统的度量来检查能够跨越决策边界的扰动样本的比例。

---


漂移样本家族：FakeDoc；最近的家族：GingerMaster

[api_call::android/telephony/SmsManager;->sendTextMessage], [call::readSMS], [permission::android.permission.DISABLE_KEYGUARD],

接收短信权限，发送短信权限，写入短信权限。

权限: android.permission.SEND_SMS , 权限: android.permission.READ_SMS , 功能: android.hardware.telephony ,

[权限::android.permission.READ_CONTACTS], [实际权限::android.permission.READ_CONTACTS],

[api_call::android/location/LocationManager;->isProviderEnabled], [api_call::android/accounts/AccountManager;->getAccounts],

意图: android.intent.category.HOME, 功能: android.hardware.location.network, 实际权限: android.permission.RESTART_PACKAGES。

权限：[real_permission::android.permission.WRITE_SETTINGS]，API 调用：[api_call::android/net/ConnectivityManager, >getAllNetworkInfo]，

[api_call::android/net/wifi/WifiManager;->setWifiEnabled], [api_call::org/apache/http/impl/client/DefaultHttpClient],

[网址::https://ws.tapjoyads.com/], [网址::https://ws.tapjoyads.com/set_publisher_user_id?],

[权限::android.permission.CHANGE_WIFI_STATE], [实际权限::android.permission.ACCESS_WIFI_STATE],

真实的权限：android.permission.BLUETOOTH，android.permission.BLUETOOTH_ADMIN，调用：setWifiEnabled。

表 5：解释为何给定样本是漂移样本的案例研究。高亮显示的特征表示那些与区分漂移样本与其最近亲本的语义特征相匹配的特征。

---


<table><thead><tr><th>方法</th><th>Drebin-FakeDoc</th><th>IDS2018-Infiltration</th></tr></thead><tr><td>随机</td><td>0%</td><td>0%</td></tr><tr><td>边界基</th><th>础</th><th>0%</th></tr><tr><td>COIN [43]</td><td>0%</td><td>0%</td></tr><tr><td>CADE</td><td>97.64%</td><td>1.41%</td></tr></table>


表 6：基于决策边界交叉的扰动样本比例的说明精确度比较。更高的比例意味着扰动的特征更为重要。

## 5.2 保真度评估结果



特征对距离的影响。表 4 显示了所有漂移样本的平均和标准差 $ {d}_{{\mathbf{x}}_{t}}^{\prime } $（即漂移样本与最近聚类中心的距离）。我们有四个关键观察点。首先，基于随机选择的特征对漂移样本进行扰动几乎不会影响隐空间距离（比较第 2 行和第 3 行）。其次，基于边界的解释方法可以在两个数据集上降低距离，百分比为 $ {26}\% - {47}\% $（比较第 2 行和第 4 行）。这表明这种方法有一定的效果。然而，绝对距离值仍然很高。第三，COIN在 IDS2018 数据集上降低了隐空间距离（比较第 2 行和第 5 行），但在 Drebin 数据集上平均距离有所增加。本质上，COIN是一种专门基于边界的方法，它使用一组线性支持向量机（LinearSVM）分类器来近似决策边界。我们发现 COIN在高维空间中效果不佳，并且很难将漂移样本拖到边界的另一侧（将在第 5.3 节讨论）。最后，CADE的解释模块在距离度量上的平均值和标准差最低。距离从原始距离显著减少（即 Drebin 数据集上的 98.8% 和 IDS2018 数据集上的 79.9%，比较第 2 行和第 6 行）。特别是，CADE在基于边界的解释方法上表现出了显著的优势。由于我们的方法克服了样本稀疏性和不平衡问题，它指出了对距离有更大影响的更有效的特征（这些特征影响漂移检测决策）。

选定特征的数量。总体而言，选定特征的数量很小，这使得手动解释成为可能。如前所述，我们配置所有方法以选择相同数量的重要特征（与 CADE 相同）。对于 Drebin 数据集，平均选定特征数为 44.7，标准差为 6.2。这仅占所有特征的极小部分（即 3%）。同样，IDS2018 数据集的平均选定特征数为 16.2，约占所有特征的 $ {20}\% $。

## 5.3 跨越决策边界

上述评估确认了所选特征对距离度量产生的影响，而这正是CADE设计用来优化的。为了提供另一个视角，我们进一步考察了所选特征对跨越边界的影响。更具体地说，我们计算了被扰动样本中成功跨越决策边界的比例。如表6所示，我们确认在大多数设置中，跨越边界在漂移检测上下文中对于大多数设置来说都是困难的。特别是，对于Drebin数据集，CADE可以将$ {97.64}\% $的扰动样本推到跨越检测边界，但对于IDS2018数据集，只有$ {1.41}\% $的样本能够跨越边界。相比之下，基线方法在原始特征空间中很少能够成功扰动漂移样本，使其跨越边界。通过放宽这一条件，并将重点放在距离变化上，我们的方法在识别重要特征方面更加有效。

## 5.4 案例研究

为了展示我们的方法确实捕获了有意义的特征，我们提供了一些案例研究。在表5中，我们为Drebin数据集展示了一个案例研究。我们选择当FakeDoc是一个未知的家族，并随机挑选一个漂移样本来运行解释模块。在我们的解释模块中，从$ {1000} + $个特征中，我们指出了42个重要的特征，其中27个特征的价值是“1”（意味着这个样本包含这些特征）。如表5所示，最近的家族是GingerMaster。

我们手动检查这些特征，以确定这些特征是否携带正确的语义含义。虽然获得“地面真相”解释很困难，但我们收集了关于FakeDoc恶意软件和Ginger-Master $ \left\lbrack {{68},{70}}\right\rbrack $的外部分析报告。根据这些报告，FakeDoc恶意软件与GingerMaster的一个关键区别是，它通常通过短信订阅付费服务并将其费用转嫁给受害用户。如表5所示，许多选中的特征与读取、写入和发送短信的权限和API调用相关。我们强调了这些与短信相关功能相关的特征。其他相关的特征也被强调了。例如，“RESTART_PACKAGES”权限允许恶意软件结束后台进程（例如，显示短信进入的进程）以避免用户注意。“DISABLE_KEYGUARD”权限允许恶意软件在不解锁屏幕的情况下发送付费短信。“WRITE_SETTINGS”也有助于秘密发送短信。“url::https://ws.tapjoyads.com/”是一个通常被FakeDoc使用的广告库。再次，这些特征是从超过1000个特征中选出的。我们得出结论，这些特征是这个样本与最近已知家族不同的一个高度指示。

## 6 评估：课堂进化



到目前为止，我们的评估主要集中在一种类型的概念漂移（类型A），其中漂移样本来自先前未见过的家庭。接下来，我们将探讨如何将我们的解决方案适应于解决另一种类型的概念漂移（类型B），其中漂移样本来自现有类别。我们在二元分类设置中进行了一个简短的实验，遵循与[38]相似的设置。

更具体地说，我们首先使用Drebin数据集训练一个二元SVM分类器，用于分类恶意软件样本与良性样本。该分类器在Drebin上的训练 $ {F}_{1} $ 分数为0.99。我们想测试这个分类器在另一个Android恶意软件数据集Marvin [42]上的表现。Marvin是一个稍新的数据集（从2010年到2014年），与Drebin（从2010年到2012年）相比。我们首先从Marvin数据集中移除与Drebin重叠的样本，以确保Marvin样本确实是未见过的。这给我们留下了9,592个良性样本和9,179个恶意软件样本在Marvin。

对于这次实验，我们随机将Marvin数据集分为验证集和测试集（50:50）。对于两组，我们保持恶意软件和良性样本的比例平衡。我们将原始分类器（在Drebin数据上训练的）应用于Marvin测试集。我们发现测试精度不再高 $ \left( {F}_{1}\right. $ 分数0.70)，这可能是由于恶意软件类别或良性类别中的内部进化。

为了解决内部进化问题，我们在Marvin验证集上应用CADE和Transcend来识别一小部分

<table><tr><td rowspan="2"># 选定样本</td><th colspan="2">$ {F}_{1} $ 的重训练分类器</th></tr><tr><td>CADE</td><td>Transcend</td></tr><tr><td>0</td><td>0.70</td><td>0.70</td></tr><tr><td>100</td><td>0.91</td><td>0.71</td></tr><tr><td>150</td><td>0.92</td><td>0.76</td></tr><tr><td>200</td><td>0.93</td><td>0.74</td></tr><tr><td>250</td><td>0.94</td><td>0.71</td></tr></table>

表7：重训练分类器在Marvin测试集上的性能。我们使用CADE和Transcend在Marvin验证集上选择漂移样本进行重新训练。

的漂移样本（它们可以是良性或恶意的）。我们模拟通过使用它们的“真实标签”来标记它们，然后将这些标记的漂移样本添加回Drebin训练数据进行重新训练。最后，我们在Marvin测试集上测试重训练的分类器。

如表7所示，我们发现CADE仍然显著优于Transcend。例如，通过添加仅150个漂移样本（Marvin验证集的 $ {1.7}\% $）进行重新训练，CADE将二元分类器的 $ {F}_{1} $ 分数提高到0.92。对于Transcend，相同数量的样本只能将 $ {F}_{1} $ 分数提高到0.74。此外，我们还发现CADE也更快：CADE的运行时间是1.2小时（与Transcend的10小时相比）。这次实验确认CADE可以适应于处理二元恶意软件分类器的内部进化。

## 7 真实世界中的PE恶意软件测试

我们与安全公司蓝六角公司合作，在其专有样本集上测试CADE。更具体地说，我们在蓝六角公司的Windows恶意软件数据库上进行了初始测试。在这个测试中，我们获得了从2019年8月29日至2020年2月10日收集的样本集的访问权限。这个集合包括来自395个家族的20,613个独特的Windows PE恶意软件样本。我们使用这个数据集在一个更加多样化的设置中测试CADE（即漂移样本来自更多的家族）。

PE恶意软件数据集。对于每个样本，我们都有原始二进制文件和Blue Hexagon提供的元数据，包括样本首次被观察的时间戳，以及家族名称（由安全分析师标注）。我们遵循Ember [6]的特征工程方法，并使用LIEF [63]来解析二进制文件并提取特征向量。每个特征向量有2,381个维度。这些特征包括字节频率直方图和不同字节的熵，可打印字符串和特殊模式，关于文件大小的特征，头信息，节信息，导入的库和函数，导出函数，以及数据目录的大小和虚拟地址。

家族归属实验。原始分类器是一个多类分类器，用于归属恶意软件家族。我们的目标是使用CADE检测不应归属于现有家族的未知家族。我们根据

<table><thead><tr><th>$ N $</th><th>精度</th><th>召回率</th><th>$ {F}_{1} $</th><th>正常努力</th><th>检测到的家族</th></tr></thead><tr><td>5</td><td>0.96</td><td>0.98</td><td>0.97</td><td>1.02</td><td>161/165</td></tr><tr><td>10</td><td>0.96</td><td>0.94</td><td>0.95</td><td>0.98</td><td>153/160</td></tr><tr><td>15</td><td>0.95</td><td>0.80</td><td>0.87</td><td>0.84</td><td>140/155</td></tr></table>


表 8：PE恶意软件数据集的漂移检测结果。$ N $ 是训练集中的已知家族数量。“检测到的家族”表示CADE检测到的所有新家族的数量。

时间。训练集包含从2019年8月29日至2020年1月10日收集的恶意软件样本。测试集包含在随后的月份收集的样本，从2020年1月10日至2020年2月10日。为了训练，我们需要确保恶意软件家族有足够的样本来训练原始分类器。因此，我们专注于前$ N $个家族。我们分别测试了三种设置，$ N = 5,{10} $和15。这确保了训练家族中每个家族至少有298个样本。不在前$ N $个家族中的样本被排除在训练集之外。对于原始分类器来说，这样的最小样本数量是必要的，以确保其有合理的准确性。例如，对于$ N = {15} $，准确率为$ {96.5}\% $。如果数据集更大，该分类器有可能支持更多的家族。对于测试集，所有家族都被保留。此外，根据Blue Hexagon分析团队的建议，我们向测试集中添加了两个家族（Tinba和Smokeloader），因为它们观察到这些家族在逃避现有的基于机器学习的恶意软件检测引擎方面更为成功。如表8所示，测试集中有155到165个以前未见过的家族，即CADE的目标。

结果与案例研究。表8显示，在具有超过155个先前未见家族的多样化样本集上，CADE仍然表现良好。当训练家族的数量 $ N = {10} $ 时，CADE实现了$ {F}_{1} $分数为$ {95}\% $。当 $ N = {15} $ 时，$ {F}_{1} $分数仍然为0.87。大多数先前未见的家庭被成功识别。确实，更多的家庭数量使得问题变得更加困难。原因不一定是由于现有家庭和未见家庭难以区分。相反，随着训练家庭数量的增加，我们观察到更多的测试样本在现有家庭中，这些样本与未见家庭的样本相比，甚至更远。这些家庭内的变体成为在我们的定义下假阳性贡献的主要因素。观察结果与我们第四部分案例研究中的观察相似。作为快速比较，我们也在 $ N = {15} $ 设置下运行了Transcend。我们发现CADE在这个 $ N = {15} $ 设置下仍然在更多样化的未见家庭上优于Transcend（Transcend的 $ {F}_{1} $ 分数仅为0.76）。

我们使用Tinba和Smokeloader的说明模块进行了快速的特征分析，这两个样本对于其底层的分类器来说都是公认的挑战性例子。Tinba（微型银行木马）针对金融网站进行浏览器内攻击和网络嗅探。Smokeloader是一种下载其他恶意软件的木马，虽然是一个古老的恶意软件家族，但它发展迅速。特别是，我们发现Tinba的新样本与现有的Wabot家族最为接近。CADE指出了45个特征以提供解释。例如，我们发现Tinba启用了“LARGE_ADDRESS_AWARE”选项，该选项告诉链接器程序可以处理大于2千兆字节的地址。这种选项在64位编译器中是默认启用的。这提供了一些解释，说明为什么Tinba能够在现有的恶意软件检测引擎中成功逃逸，因为绝大多数PE恶意软件文件是基于32位的。根据“部分”的特征，我们注意到Tinba样本使用了“UPX”作为打包器。根据导入的库和函数的选定特征，我们发现Tinba引用了“crypt32.dll”用于加密字符串。Tinba样本在这些特征上与Wabot样本不同。

## 8 讨论

计算复杂性。CADE的计算开销小于现有的方法。检测模块的复杂性包含两部分：对比学习和对流检测。对比学习的复杂性是 $ O\left( {I{B}^{2}\left| \theta \right| }\right) $，其中 $ I, B $ 和 $ \left| \theta \right| $ 分别代表训练迭代次数、批大小和自动编码器模型的参数数量。对流检测（算法1）的复杂性是 $ O\left( {N{\widetilde{n}}_{i} + {NK}}\right) $，其中 $ N,{\widetilde{n}}_{i} $ 和 $ K $ 分别代表类别数量、每个类别的最大训练样本数量和测试样本数量。CADE检测模块的整体复杂性是 $ O\left( {I{B}^{2}\left| \theta \right| + N{\widetilde{n}}_{i} + {NK}}\right) $。我们的训练开销是可接受的，因为它仅与批大小 $ B $ 成二次关系。我们的检测运行时开销远低于Transcend（其复杂性为 $ O\left( {N{\widetilde{n}}_{i}K}\right) $）。经验上，我们在第4节记录了检测实验的平均运行时间，并确认CADE比Transcend快。例如，在更大的IDS2018数据集上，CADE和Transcend的平均运行时间分别为1,422.7s和4,289.3s。至于解释模块，CADE与基于边界的解释方法（如COIN）相当。例如，对于IDS2018数据集，CADE、COIN和基于边界的解释方法解释一个流样本的平均运行时间分别为 $ {3.2}\mathrm{\;s},{8.2}\mathrm{\;s} $ 和 $ {3.7}\mathrm{\;s} $。基于边界的解释方法还需要平均额外 $ {76.5}\mathrm{\;s} $ 来为解释构建近似模型。


解释 vs. 对抗性攻击。我们注意到CADE中的解释模块与对抗性示例生成过程有一些相似之处，例如，两者都涉及对给定输入进行特定目标的扰动。然而，我们认为它们有两大不同之处。首先，它们的输出不同。对抗性攻击（旨在逃避）直接输出跨越决策边界所需的扰动；我们的解释方法（旨在理解漂移）输出影响距离的重要特征。其次，它们对扰动的约束不同。我们的解释方法只尝试最小化扰动特征的数量，而对抗性攻击还对扰动的幅度进行了限制。更重要的是，对抗性样本需要在各自的应用中有效（即有效的恶意软件样本，可以执行并保持恶意行为，有效的网络流量，可以执行原始攻击）。因此，生成对抗性样本在我们的上下文中可能比推导解释更困难。也就是说，对抗性攻击超出了本文的范围。我们将CADE的对抗性攻击留待将来研究（即创建非感知扰动，将漂移样本转换为分布内的样本）。

限制与未来工作。我们的工作有几个限制。首先，CADE对所有漂移样本进行单一列表排名。然而，在实践中，漂移样本可能包含子结构（例如，多个新恶意软件家族）。一种实用的策略可能是进一步将漂移样本分组为簇。这样，安全分析师只需检查和解释每个簇的代表性样本，以进一步节省时间。其次，CADE的某些超参数是经验确定的（例如，MAD阈值）。我们在附录C中测试了CADE对超参数的敏感性。未来的工作可以研究更系统的策略来配置超参数。第三，CADE是基于假设训练集没有误标样本（或中毒样本）而设计的。我们将未来的工作推迟到对我们的系统进行低质量或恶意标签的鲁棒化。第四，我们的实验主要集中在检测新家族上。在第六节中，我们仅简要实验了现有家族内的概念漂移（类内进化）。我们将更深入的分析推迟到未来的工作。

最终，我们在第7节中的评估仅限于$ N = {15} $个训练类别（以及155个先前未见过的测试类别）。我们将$ N $限制为$ {15} $，以确保每个训练类别的样本数量足够训练一个准确的原始分类器。为了测试更大的$ N $，我们尝试将CADE应用于多个其他恶意软件数据集，但没有找到一个满足我们需求的数据集。例如，Ember-2018数据集[6]提供了大量恶意软件样本。然而，家族标签并不完善。例如，Ember-2018中的一个流行恶意软件家族名为“high”（有8,417个样本），这实际上是从VirusTotal报告中错误解析的：报告中的原始条目名称为“恶意（高度信心）”，这不是一个真实的恶意软件家族名称。我们观察到标签中存在其他类似的解析错误和不一致性。Ember-2017数据集[6]和UCSB打包恶意软件数据集[3]不提供恶意软件家族信息。Microsoft恶意软件分类挑战赛的数据集[55]只有9个恶意软件家族，这比我们的Blue Hexagon数据集要小。鉴于我们的努力失败，我们将对更大数量的训练类别的检查推迟到未来的工作。

## 9 相关工作

安全领域中使用的机器学习。机器学习已经被用来解决许多安全问题，如恶意软件检测 $ \left\lbrack {6,7,{17},{42}}\right\rbrack $，恶意软件家族归属 $ \left\lbrack {4,{11}}\right\rbrack $，网络入侵检测 $ \left\lbrack {{24},{34},{48},{60}}\right\rbrack $。最近，研究人员开始研究使用深度学习方法进行二进制分析 $ \left\lbrack {{27},{69}}\right\rbrack $，软件漏洞识别 [72]，和严重性预测 [30]。这些机器学习模型中的大多数在实践中需要解决概念漂移问题。

环境检测。最近，机器学习社区在环境检测方面取得了进展 $ \left\lbrack {{14},{32},{41},{46},{49}}\right\rbrack $ 。这些工作相关，但与我们工作的假设和目标不同。在较高层次上，这些方法大多试图校准原始分类器生成的“概率”以检测环境样本。研究人员确实认识到了当涉及到未知的分布时，概率可能是不可信的 $ \left\lbrack {{14},{32}}\right\rbrack $ 。为了避免给环境样本分配一个高的概率，所提出的方法通常需要引入一个辅助的环境数据集到训练数据中。这些方法在安全应用中很难实现，原因有两个。首先，辅助环境数据集（即未知的攻击）在最初就很难获得。其次，这些解决方案需要重新设计原始分类器（例如，功能性恶意软件检测器），这在生产环境中不方便进行。相反，我们的方法不依赖于辅助环境数据集，并且与原始分类器脱钩。

分类可信度。相关的工作旨在评估分类结果的可信度，例如 $ \left\lbrack {{11},{37},{50}}\right\rbrack $。一个共同的目标是识别不可信的预测，例如对抗性攻击的预测。这些方法大多基于“最近邻”的概念。直觉是，不可信的预测更有可能与其最近邻训练样本不同标签。例如，DkNN [50] 通过比较测试样本与其在深度神经网络（DNN）每一层的邻近训练样本来推导信任分数。另一项最近的工作 [37] 基于“高密度集”计算信任分数。然而，这样的基于邻居的方法仍然依赖于一个好的距离函数。正如 [37] 所承认的，他们的方法在高维空间中可能会遇到问题。总体而言，这些方法与我们关注的领域不同。他们的目标是识别现有类别内的误分类（而不是从新类别漂移的样本）。与此方向相关，主动学习方法也使用预测概率来选择低信心样本进行重新标记 $ \left\lbrack {{47},{73}}\right\rbrack $。如前所述（见 [32]），在概念漂移下，预测概率本身可能是误导性的。

机器学习解释。最近的工作集中于对机器学习分类器的后验解释方法的研究 $ \left\lbrack {8,{22},{35},{58},{59}}\right\rbrack $ ，并研究解释的鲁棒性 $ \left\lbrack {{15},{71}}\right\rbrack $ 。给定一个测试样本，目标是 pinpoint 重要的特征来解释分类决策。大多数方法是为深度神经网络设计的。例如，基于扰动的方 法会微妙地操纵输入，观察输出变化来识别重要的特征 $ \left\lbrack {{13},{18},{21},{22}}\right\rbrack $ 。基于梯度的方法（例如，saliency maps）通过深度神经网络反向传播梯度来衡量每个特征的敏感性 $ \left\lbrack {{56},{58},{59},{61}}\right\rbrack $ 。其他解释方法将目标分类器视为黑盒 [53,54]。像LIME [53]、LEMNA [28] 和 SHAP [44]这样的系统尝试使用更简单的模型（例如，线性回归）来近似输入样本附近的决策边界，然后使用更简单的模型来 pinpoint 特征以生成解释。

我们的方法属于基于扰动的类别。关键的区别在于，现有方法是为监督分类器设计的，旨在解释决策边界。我们的方法专注于解释距离变化，这些变化更适合于异常点检测。只有少数工作试图解释无监督模型（[19], [43]）。我们在评估中使用了COIN [43] 作为基线，并展示了基于距离的解释的优势。

## 结论

在本论文中，我们构建了一个名为CADE的全新系统，以补充监督分类器，以对抗安全情境中的概念漂移。通过对比自编码器和基于距离的解释方法，CADE被设计用来检测从原始训练分布中偏离的漂移样本，并提供相应的解释来解释漂移的意义。通过使用各种数据集，我们展示了CADE在性能上超过了现有方法。与一家行业合作伙伴合作，我们演示了CADE能够检测和解释来自先前未见过的家族的漂移样本的能力。

致谢



我们感谢我们的导师David Freeman和匿名审稿人提出的建设性评论和建议。这项工作部分得到了NSF资助CNS-2030521和CNS-1717028的支持，以及亚马逊研究奖的资助。

参考文献

[1] 马丁·阿巴迪（Martín Abadi），保罗·巴尔汉姆（Paul Barham），简明·陈（Jianmin Chen），张峰（Zhifeng Chen），安迪·戴维森（Andy Davis），杰弗里·德恩（Jeffrey Dean），马修·德文（Matthieu Devin），桑杰·盖马沃（Sanjay Ghemawat），盖伊·伊文（Geoffrey Irving），迈克尔·伊斯尔（Michael Isard），等。Tensorflow：大规模机器学习系统。在Proc. of USENIX OSDI，2016年。


[2] Hervé Abdi 和 Lynne J. Williams. 主成分分析。WIREs 计算统计，2010年。

[3] 霍贾特·阿加哈尼（Hojjat Aghakhani），法比奥·格里蒂（Fabio Gritti），弗朗西斯科·梅卡（Francesco Mecca），马蒂娜·林多弗（Martina Lindorfer），斯蒂芬诺·奥尔托兰尼（Stefano Ortolani），达维德·巴尔扎科蒂（Davide Balzarotti），乔瓦尼·维加（Giovanni Vigna）和克里斯托弗·克鲁格（Christopher Kruegel）。当恶意软件是“热包装”；基于静态分析特征的机器学习分类器的限制。在Proc. of NDSS上，2020年。

[4] 曼苏尔·阿哈米迪（Mansour Ahmadi），德米特里·乌利扬诺夫（Dmitry Ulyanov），斯坦尼斯拉夫·塞门诺夫（Stanislav Semenov），米哈伊尔·特罗菲莫夫（Mikhail Trofimov）和乔治·贾钦托（Giorgio Giacinto）。新型特征提取、选择和融合，用于有效恶意软件家族分类。在Proc. of CO-DASPY，2016年。

[5] 布鲁斯·安。更多广告软件和磷虾变种出现在应用商店中。趋势科技，2012。

[6] Hyrum S Anderson 和 Phil Roth. Ember: 一个用于训练静态 PE 恶意软件机器学习模型的开放式数据集。arXiv 预印本arXiv:1804.04637，2018年。

[7] Daniel Arp, Michael Spreitzenbarth, Malte Hubner, Hugo Gascon, Konrad Rieck, 和 CERT Siemens 的检测。Drebin：在您的口袋中有效地和可解释地检测 Android 恶意软件。在 Proc. of NDSS 的第 2014 页。

[8] Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, 和 Wojciech Samek. 关于非线性分类器决策的像素级解释：逐层相关性传播法。PloS one, 2015。

[9] 马努埃尔·贝纳-加西亚，何塞·德尔·科尔波-阿维拉，拉乌尔·菲达尔戈，阿尔伯特·比费特，R Gavalda，和 R 莫雷尔斯-布埃诺。早期漂移检测方法。在第四届数据流知识发现国际研讨会，2006年。

[10] Albert Bifet 和 Ricard Gavalda. 使用自适应窗口学习随时间变化的数据。在 Proc. of SDM 上的论文。2007年。

[11] 塔姆奥·查克拉博蒂（Tanmoy Chakraborty），法比奥·皮埃拉齐（Fabio Pierazzi）和VS苏布拉曼尼亚（VS Subrahmanian）。Ec2：用于预测安卓恶意软件家族的聚类和分类的集合。TDSC，2017年。

[12] Eshwar Chandrasekharan, Mattia Samory, Anirudh Srinivasan, 和 Eric Gilbert. 社区袋: 使用现有互联网数据识别在线滥用行为。在 Proc. of CHI 上，2017 年。

[13] Chun-Hao Chang, Elliot Creager, Anna Goldenberg, 和 David Duvenaud. 解释图像分类器通过反事实生成。在 Proc. of ICLR 上，2019 年。

[14] 陈杰峰, 李逸轩, 吴希, 李莹玉, 和 Somesh Jha. 神经网络中的鲁棒出分布检测. arXiv预印本, arXiv:2003.09711, 2020年.

[15] 陈杰峰, 吴希, 维亚巴夫·拉斯托吉, 杨宇, 和 Somesh Jha. 稳健的归因正则化。在 Proc. of NeurIPS 上，2019 年。

[16] Ting Chen, Simon Kornblith, Mohammad Norouzi, 和 Geoffrey Hinton. 一种简单的框架，用于对比学习视觉表征。arXiv:2002.05709，2020年。

[17] Yizheng Chen, Shiqi Wang, Dongdong She, and Suman Jana. On training robust pdf malware classifiers. In Proc. of USENIX Security, 2020.


[18] Piotr Dabkowski 和 Yarin Gal. 实时图像显著性对于黑箱分类器。在 Proc. of NeurIPS 上，2017 年。

[19] Xuan Hong Dang, Ira Assent, Raymond T Ng, Arthur Zimek, 和 Erich Schubert. 识别和解释离群值的判别特征。在Proc. of ICDE上，2014年。

[20] Denis Moreira dos Reis, Peter Flach, Stan Matwin, 和 Gustavo Batista. 快速无监督在线漂移检测使用增量kolmogorov-smirnov测试。在Proc. of $ {KDD},{2016} $ 上。

[21] Ruth C Fong, Mandela Patrick, 和 Andrea Vedaldi. 理解深度网络通过极值扰动和光滑掩码。在 Proc. of ICCV 上，2019 年。

[22] Ruth C Fong 與 Andrea Vedaldi. 通過有意義的干擾解釋黑盒子的可解釋性。在 Proc. of ICCV 會議論文集中，2017 年。

translated text.

[23] 若昂·加马、因德里·兹利奥贝蒂、阿尔伯特·比费、米科拉·佩切尼齐耶和阿卜杜勒哈米德·布恰亚。概念漂移适应性综述。ACM计算机调查（CSUR），2014年。

异常基于网络入侵检测：技术、系统和挑战。

[25] Ian J Goodfellow, Jonathon Shlens, 和 Christian Szegedy. 解释和利用对抗性例子。Proc. of ICLR, 2015。

[26] Antonio Gulli 和 Sujit Pal. 深度学习与 Keras. 2017年。

[27] 郭文博, 穆东良, 邢新宇, 杜敏, 和 唐娜·宋. 深度vsa: 使用深度学习加速程序分析的死亡后价值集分析. 在美国计算机安全会议上的论文. 2019年.

[28] 郭文博, 穆东良, 徐俊, 苏普瑞, 王刚, 和 邢新宇. Lemna: 解释基于深度学习的网络安全应用。在 Proc. of CCS 上，2018 年。

[29] Raia Hadsell, Sumit Chopra 和 Yann LeCun. 通过学习不变映射进行维度减少。在 Proc. of CVPR 上的论文。2006年。

[30] Han Zhuobing, Li Xiaohong, Xing Zhenchang, Liu Hongtao, 
Feng Zhiyong. 仅使用漏洞描述学习预测软件漏洞严重性。在ICSME上发表的论文，2017年。

[31] מאין הראל, שי מנור, רן אל-יניב, וקובי קרמר. חיפוש שינוי ראשון דרך מחלקת תרשיות. באירועים של ICML, 2014.


[32] 丹·亨德利克斯和凯文·金普尔。神经网络中检测误分类和出分布示例的基线。在Proc. of ICLR上，2017年。

[33] 杰弗里·H·欣顿和鲁斯兰·R·萨拉霍季诺夫。使用神经网络降低数据的维度。科学，2006年。

[34] Elike Hodo, Xavier Bellekens, Andrew Hamilton, Christos Tachtatzis, 和 Robert Atkinson. 浅层和深层网络入侵检测系统：一种分类法和调查。arXiv预印本arXiv:1701.02145，2017年。

[35] 萨拉·霍克（Sara Hooker），杜米特鲁·埃尔汉（Dumitru Erhan），皮埃尔-让·肯德曼斯（Pieter-Jan Kindermans）和本·金（Been Kim）。深度神经网络中的可解释性方法基准。在NeurIPS的Proc.中，2019年。

[36] Steve TK Jan, Qingying Hao, Tianrui Hu, Jiameng Pu, Sonal Oswal, Gang Wang, and Bimal Viswanath. 黑暗中掷镖？使用有限数据和神经数据增强检测机器人。在《Proc. of $ S\& P $》，2020年。

[37] 海因里希·Jiang, 被恩·Kim, 旋律·Guan, 和 玛雅·Gupta。信任或不信任一个分类器。在 Proc. of NeurIPS 上的论文，2018 年。

[38] 罗伯托·乔丹尼，库马尔·夏拉德，桑坦古·K·达什，智·王，达维德·帕皮尼，伊利亚·诺雷丁夫，洛伦佐·卡瓦拉罗。超越：检测恶意软件分类模型中的概念漂移。在Proc. of USENIX Security，2017年。

[39] Alex Kantchelian, Sadia Afroz, Ling Huang, Aylin Caliskan Islam, Brad Miller, Michael Carl Tschantz, Rachel Greenstadt, Anthony D. Joseph, 和 J. D. Tygar. 对抗性漂移的方法。在 Proc. of AISec 的 2013 年。

[40] Christophe Leys, Christophe Ley, Olivier Klein, Philippe Bernard, 和 Laurent Licata. 检测异常点：不要使用平均值的标准差，使用中位数周围的标准差。Journal of Experimental Social Psychology, 2013年。

[41] 梁世玉, 李一轩, 和 Srikant Rayadurgam. 增强神经网络中图像出分布检测的可靠性。ICLR会议论文集, 2018年。

[42] 马丁娜·林多夫勒、马提亚斯·纽格施瓦尔登特纳和克里斯蒂安·普拉策尔。Marvin：通过静态和动态分析高效且全面地分类移动应用程序。在COMPSAC的教授中，2015年。

[43] Ninghao Liu, Donghwa Shin, and Xia Hu. 上下文异常点解释。在 Proc. of IJCAI，2018。

[44] Scott M. Lundberg 和 Su-In Lee. 一种统一的模型预测解释方法。在 Proc. of NeurIPS 上，2017 年。

[45] Chris J Maddison, Andriy Mnih, 和 Yee Whye Teh. 混凝土分布：离散随机变量的连续松弛。在 Proc. of ICLR 上，2017 年。

[46] Marc Masana, Idoia Ruiz, Joan Serrat, Joost van de Weijer, 和 Antonio M Lopez. 用于新颖性和异常检测的度量学习。在 Proc. of BMVC 上，2018 年。

[47] Brad Miller, Alex Kantchelian, Sadia Afroz, Rekha Bachwani, Edwin Dauber, Ling Huang, Michael Carl Tschantz, Anthony D. Joseph, 和 J.D. Tygar. 对抗性主动学习。在 Proc. of AISec，2014年。

[48] Yisroel Mirsky, Tomer Doitshman, Yuval Elovici, 和 Asaf Shabtai. Kitsune: 一个自动编码器集合的在线网络入侵检测。在 Proc. of NDSS 上，2018 年。

[49] 亚里士提莱斯-安杰洛斯·帕帕多普洛斯 (Aristotelis-Angelos Papadopoulos), 莫哈默德·雷扎·拉吉蒂 (Mohammad Reza Rajati), 纳西姆·夏伊克 (Nazim Shaikh), 和 贾迈因·王 (Jiamian Wang). 带有信心控制的异常点暴露用于异常检测。arXiv预印本arXiv:1906.03509，2019年。

[50] Nicolas Papernot 和 Patrick McDaniel. Deep k-最近邻: 向自信、可解释和鲁棒的深度学习迈进。arXiv预印本arXiv:1803.04765, 2018年。

[51] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vander-plas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, 和 E. Duch-esnay. Scikit-learn: Python 中的机器学习。Journal of Machine Learning Research, 2011.

[52] 费格努斯·彭德尔伯里（Feargus Pendlebury），法比奥·皮埃拉齐（Fabio Pierazzi），罗伯托·乔丹尼（Roberto Jordaney），约纳斯·基德（Johannes Kinder）和洛伦佐·卡瓦拉罗（Lorenzo Cavallaro）。TESSERACT：消除空间和时间跨度上的恶意软件分类实验偏差。在USENIX安全会议上的论文，2019年。

为什么应该信任你？解释任何分类器的预测。在KDD会议上的论文。2016年。

[54] Marco Tulio Ribeiro, Sameer Singh, 和 Carlos Guestrin. Anchors: 高精度的模型无关解释。在 Proc. of AAAI, 2018 年。

[55] Royi Ronen, Marian Radu, Corina Feuerstein, Elad Yom-Tov, 和 Man-sour Ahmadi. Microsoft恶意软件分类挑战。arXiv预出版arXiv:1802.10135, 2018年。

[56] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, 和 Dhruv Batra. Grad-cam: 基于梯度定位的深度网络视觉解释。在Proc. of ICCV上，2017年。

[57] 伊曼·沙拉法迪尼（Iman Sharafaldin），阿扎什·哈比比·拉什卡里（Arash Habibi Lashkari）和阿里·A·戈尔巴尼（Ali A Ghorbani）。朝向生成一个新的入侵检测数据集和入侵流量特性化。在Prof. of ICISSP，2018年。

[58] Avanti Shrikumar, Peyton Greenside, 和 Anshul Kundaje. 通过传播激活差异学习重要特征。在 Proc. of ICML 上，2017 年。

[59] Karen Simonyan, Andrea Vedaldi, 和 Andrew Zisserman. 深入卷积网络: 可视化图像分类模型和关注图. ICLR 工作坊, 2014年.

[60] Robin Sommer 和 Vern Paxson. 走出封闭世界：关于使用机器学习进行网络入侵检测。在 Proc. of S&P 会议上。2010 年。

[61] Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, 和 Martin Riedmiller. 追求简单性：全卷积网络。在 Proc. of ICLR 上，2015 年。

[62] 穆昆德·桑达拉拉詹（Mukund Sundararajan），安库尔·塔利（Ankur Taly）和奇奇·杨（Qiqi Yan）。深度网络的公理归因。在ICML的论文中，2017年。

[63] Romain Thomas. Lief - 图书馆用于测量可执行格式。https://lief.quarkslab.com/，2017年4月。

translated text.

[64] 罗伯特·泰斯希里尼和格特·瓦尔特。通过预测强度验证簇。《计算和图形统计学杂志》，2005年。

[65] Daniele Ucci, Leonardo Aniello, 和 Roberto Baldoni. 恶意软件分析中机器学习技术的调查. 计算机安全, 2019.

[66] Laurens van der Maaten 和 Geoffrey Hinton. 使用t-SNE可视化数据。Journal of Machine Learning Research, 2008年。

[67] 亚历山大·瓦尔尼克（Alexander Warnecke），丹尼尔·阿普（Daniel Arp），克里斯蒂安·弗伦泽格（Christian Wressnegger）和康拉德·里埃克（Konrad Rieck）。不要把它漆成黑色：深度学习在计算机安全中的白盒解释。在Euro S&P的会议上。2020年。

[68] Fengguo Wei, Yuping Li, Sankardas Roy, Xinming Ou, and Wu Zhou. 深度分析当前Android恶意软件的真实值。在Proc. of DIMVA上，2017年。

[69] Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn Song. 基于神经网络的图嵌入方法用于跨平台二进制代码相似性检测。在Proc. of CCS上发表，2017年。

[70] Rowland Yu. 酒窖大师：一个Android恶意软件案例研究。在病毒子弹会议，2013年。

[71] 张新阳, 王宁飞, 季守岭, 申华, 汪婷婷. 火力下的深度学习解释性. 美国USENIX安全会议论文集, 2020.

[72] 周亚琴, 刘尚清, 杨景凯, 杜晓宁, 和 柳阳. Devign: 通过学习综合程序语义的图神经网络有效识别漏洞。在 Proc. of NeurIPS 上，2019 年。

[73] 朱敬波, 王慧珍, 胡维恩, 和 马 马. 基于信心的主动学习数据标注停止准则. ACM 语音与语言处理杂志, 2010.

[74] Arthur Zimek, Erich Schubert, 和 Hans-Peter Kriegel. 高维数值数据中无监督异常检测的调查。Statistical Analysis and Data Mining, 2012年。

## 附录 A：边界基于解释

为了执行边界基于解释，我们首先需要用参数化函数近似漂移检测模块的检测边界。我们需要进行近似，因为漂移检测器的真实边界是基于阈值的，而不是参数化的。具体来说，我们使用一个多层感知器（MLP）在隐空间中执行近似。由于漂移样本的数量有限，为了近似决策边界，我们首先通过向检测漂移样本的隐表示中添加高斯噪声来合成更多的漂移样本。然后，我们训练一个MLP $ g\left( \mathbf{z}\right) $来区分来自漂移样本的样本分布的隐表示。在获得近似模型后，我们将它与对比自编码器 $ f $结合起来，构建一个监督近似检测模块（即 $ g\left( {f\left( \mathbf{x}\right) }\right) $）。我们在隐空间中而不是输入空间中进行近似，原因有两个。首先，在低维空间中训练一个MLP比在高维空间中更有效率。其次，直接使用原始对比自编码器比用另一个网络近似自编码器，可以实现更高的监督近似精度。使用监督近似，然后我们应用基于扰动的解释方法 [22] 来解释每个漂移样本。与CADE类似，这种方法也会输出一个掩码，指示特征的重要性。我们将 $ {\mathbf{m}}_{i} $ 进行排名，并指出具有高 $ {\mathbf{m}}_{i} $ 的特征作为重要的特征。

# 附录 B：CADE 实现细节

CADE。我们基于 Keras [26] 包和 Tensorflow [1] 作为后端实现了 CADE。CADE 和基线的超参数配置如下。对于 CADE，我们设定了编码器为 MLP，Drebin 数据集的架构为 1340-512-128-32-7（当使用不同家族作为未见家族时，第一个维度可能会变化），IDS2018 数据集的架构为 83-64-32-16-3。每个隐藏层的激活函数是 ReLU 函数。我们应用了学习率为 0.0001 的 Adam 优化器，训练了 250 个轮次来训练两个网络。Drebin 和 IDS2018 的批量大小分别为 32 和 256。对于方程 (1) 中提到的对比损失超参数，我们设定了 $ \lambda = {0.1} $ 和 $ m = {10} $。我们应用了广泛使用的经验值作为 MAD 阈值和系数：$ {T}_{\mathrm{{MAD}}} = {3.5} $ 和 $ b = {1.4826} $。对于方程 (2) 中提到的解释损失超参数，我们设定了 $ {\lambda }_{1} = {1e} - 3 $，并使用学习率为 0.01 的 Adam 优化器来解决优化函数。训练轮次设置为 250。

漂移检测基线。我们的系统没有使用对比学习，而是作为变体的 vanilla autoencoder 基线。我们还根据作者提供的源代码实现了 Transcend 的多类版本。vanilla AE 基线的超参数与 CADE 几乎相同，除了 MAD 阈值 $ {T}_{MAD} = 0 $。我们尝试了 $ {T}_{MAD} = {3.5} $ 的方法，结果为零精确度和召回率。原因是 vanilla AE 的隐空间中的距离没有被优化来比较不同的样本，因此 MAD 失去了其有效性。

对于 Transcend，我们使用了一个 MLP 架构，Drebin 数据集为 1340-100-30-7，IDS2018 数据集为 83-30-3，来训练一个多类分类器。然后我们使用负输出概率 $ - p $ 作为 Transcend 的非一致性度量。我们设定了可信度 $ p $ 值的阈值为 1.0。也就是说，如果测试样本的 $ p $ 值低于 1.0，则将其标记为漂移样本。

解释基线。我们根据主文本描述实现了边界解释方法和随机选择方法。对于 COIN，我们使用了作者发布的源代码作为实现。$ {}^{5} $ 在边界解释方法中，近似函数 $ g $ 的网络架构分别为 Drebin 和 IDS2018 的 7-15-2 和 3-15-2。优化器、批量大小和轮次与我们的系统相同。

<table><tr><td rowspan="2">参数</td><th colspan="2">Drebin $ \left( {\mathrm{{Avg}} \pm \mathrm{{Std}}}\right) $</th><th colspan="2">IDS2018 (Avg $ \pm $ Std)</th></tr><tr><td>$ {F}_{1} $</td><td>Norm. Effort</td><td>$ {F}_{1} $</td><td>Norm. Effort</td></tr><tr><td>$ m = 5 $</td><td>$ {0.95} \pm {0.05} $</td><td>$ {0.97} \pm {0.05} $</td><td>$ {0.72} \pm {0.39} $</td><td>$ {0.72} \pm {0.39} $</td></tr><tr><td>$ m = {10} $</td><td>$ {0.96} \pm {0.03} $</td><td>$ {1.00} \pm {0.09} $</td><td>$ {0.96} \pm {0.06} $</td><td>$ {0.95} \pm {0.07} $</td></tr><tr><td>$ m = {15} $</td><td>$ {0.91} \pm {0.06} $</td><td>$ {1.00} \pm {0.14} $</td><td>$ {0.77} \pm {0.33} $</td><td>$ {0.76} \pm {0.34} $</td></tr><tr><td>$ m = {20} $</td><td>$ {0.93} \pm {0.03} $</td><td>$ {1.06} \pm {0.13} $</td><td>$ {0.98} \pm {0.02} $</td><td>$ {1.02} \pm {0.02} $</td></tr><tr><td>$ \lambda = 1 $</td><td>$ {0.95} \pm {0.03} $</td><td>$ {1.05} \pm {0.11} $</td><td>$ {0.94} \pm {0.09} $</td><td>$ {1.00} \pm {0.00} $</td></tr><tr><td>$ \lambda = {0.1} $</td><td>$ {0.96} \pm {0.03} $</td><td>$ {1.00} \pm {0.09} $</td><td>$ {0.96} \pm {0.06} $</td><td>$ {0.95} \pm {0.07} $</td></tr><tr><td>$ \lambda = {0.01} $</td><td>$ {0.94} \pm {0.03} $</td><td>$ {1.05} \pm {0.09} $</td><td>$ {0.67} \pm {0.47} $</td><td>$ {0.71} \pm {0.42} $</td></tr><tr><td>$ \lambda = {0.001} $</td><td>$ {0.89} \pm {0.10} $</td><td>$ {1.19} \pm {0.33} $</td><td>$ {0.95} \pm {0.05} $</td><td>$ {0.93} \pm {0.08} $</td></tr><tr><td>$ {T}_{MAD} = {2.0} $</td><td>$ {0.96} \pm {0.03} $</td><td>$ {1.00} \pm {0.09} $</td><td>$ {0.94} \pm {0.09} $</td><td>$ {0.99} \pm {0.02} $</td></tr><tr><td>$ {T}_{MAD} = {2.5} $</td><td>$ {0.96} \pm {0.03} $</td><td>$ {1.00} \pm {0.09} $</td><td>$ {0.95} \pm {0.07} $</td><td>$ {0.97} \pm {0.04} $</td></tr><tr><td>$ {T}_{MAD} = {3.0} $</td><td>$ {0.96} \pm {0.03} $</td><td>$ {1.00} \pm {0.09} $</td><td>$ {0.95} \pm {0.07} $</td><td>$ {0.96} \pm {0.05} $</td></tr><tr><td>$ {T}_{MAD} = {3.5} $</td><td>$ {0.96} \pm {0.03} $</td><td>$ {1.00} \pm {0.09} $</td><td>$ {0.96} \pm {0.06} $</td><td>$ {0.95} \pm {0.07} $</td></tr></table>

# 附录 C：超参数敏感性

在 3.2 节中，对比自编码器的损失函数有两个超参数：$ \lambda $ 和 $ m $。在这里，我们评估 CADE 性能对这些超参数的敏感性。我们的实验方法是在固定一个参数的同时交换另一个参数。我们固定 $ \lambda $ 为 0.1，并设置 $ m $ 为 5,10,15，

<table><thead><tr><th>抽样率</th><th>10%</th><th>15%</th><th>20%</th><th>25%</th><th>30%</th></tr></thead><tr><td>$ {F}_{1} $ 分数</td><td>0.96</td><td>0.98</td><td>0.98</td><td>0.98</td><td>0.97</td></tr></table>

表 11：IDS2018 数据集的抽样率与 CADE 的 $ {F}_{1} $ 分数。

20. 如表 9 所示，当 $ m = 5 $ 和 $ m = 10 $ 时，CADE 在 Drebin 数据集上实现了较高的 $ {F}_{1} $ 分数，但在 $ m = 15 $ 和 $ m = 20 $ 时略有下降。在 IDS2018 数据集上的检测性能在 $ m $ 设置为较高值时良好，例如 $ m = 20 $。请记住，$ m $ 是控制将被考虑的距离上限的阈值。只有当两个样本的距离在 $ m $ 半径内时，它们的不相似对才能对损失函数做出贡献。因此，如果数据集更加分散和嘈杂，则可以将 $ m $ 设置为更高。

为了测试 $ \lambda $ 的影响，我们像之前一样固定 $ m = 10 $，并设置 $ \lambda $ 为 1, 0.1, 0.01 和 0.001。$ \lambda $ 控制对比损失的重要性。从表 9 可以看出，如果 $ \lambda $ 太小，它就会损害 CADE 的性能。结果证实了对比损失的重要性。

在算法 1 中，我们设定了 MAD $ {T}_{MAD} $ 的阈值为 3.5，这是一个经验值 [40]。我们也测试了其他常用的 MAD 阈值，如 2, 2.5, 3。较小的 MAD 阈值可以检测更多的样本作为潜在的漂移样本，但它可能不会影响排名过程。如表 9 所示，检测到的漂移样本的平均结果与 Drebin 和 IDS2018 数据集上的 $ {T}_{MAD} = 3.5 $ 相同，表明 $ {T}_{MAD} $ 对检测漂移样本的影响较小。

为了评估损失函数 (Eqn.(2)) 中距离基解释的超参数 $ {\lambda }_{1} $ 的敏感性，我们设定了 $ {\lambda }_{1} $ 为 $ 0.1, 0.01, 0.001 $ 和 0.0001。如表 10 所示，我们注意到 Drebin 和 IDS2018 数据集上的最近邻中心距平均值随着 $ {\lambda }_{1} $ 的减小而减小。此外，较小的 $ {\lambda }_{1} $ 可以将扰动样本穿越决策边界的比例从 Drebin-FakeDoc 的 $ 91.34\% $ 增加到 $ 99.21\% $。对于 IDS-Infiltration，比例在不同 $ {\lambda }_{1} $ 值之间有所波动，但总体而言，不同的 $ {\lambda }_{1} $ 值对评估指标没有显著差异。

## 附录 D: IDS2018 额外结果

在我们的实验中，我们仅从 IDS2018 数据集中抽取了 $ {10}\% $ 的网络流量。流量抽样是入侵检测中常见的一种方法，它使我们能够全面测试不同的实验设置。我们还发现，包含更多的流量只会增加计算开销，并且对性能的影响微乎其微。如表 11 所示，随着抽样率的增加，CADE 的 $ {F}_{1} $ 分数保持一致的高水平。

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://nonbliss.github.io">Nanbu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://nonbliss.github.io/2024/07/14/CADE-%E6%A3%80%E6%B5%8B%E5%92%8C%E8%A7%A3%E9%87%8A%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E6%A6%82%E5%BF%B5%E6%BC%82%E7%A7%BB%E6%A0%B7%E6%9C%AC/">https://nonbliss.github.io/2024/07/14/CADE-%E6%A3%80%E6%B5%8B%E5%92%8C%E8%A7%A3%E9%87%8A%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E6%A6%82%E5%BF%B5%E6%BC%82%E7%A7%BB%E6%A0%B7%E6%9C%AC/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://nonbliss.github.io" target="_blank">Nanbu's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/tag.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/12/02/23-PR-AE-%E5%9F%B9%E8%AE%AD/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/tag.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">23 PR/AE 培训</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%A4%B4%E5%83%8Fplus.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Nanbu</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://space.bilibili.com/28605906"><i class="/img/bilibili.ico"></i><span>我的B站主页~</span></a></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/14/CADE-%E6%A3%80%E6%B5%8B%E5%92%8C%E8%A7%A3%E9%87%8A%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E6%A6%82%E5%BF%B5%E6%BC%82%E7%A7%BB%E6%A0%B7%E6%9C%AC/" title="CADE: 检测和解释安全应用中的概念漂移样本">CADE: 检测和解释安全应用中的概念漂移样本</a><time datetime="2024-07-14T01:31:48.000Z" title="发表于 2024-07-14 09:31:48">2024-07-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/12/02/23-PR-AE-%E5%9F%B9%E8%AE%AD/" title="23 PR/AE 培训">23 PR/AE 培训</a><time datetime="2023-12-02T12:15:41.000Z" title="发表于 2023-12-02 20:15:41">2023-12-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/26/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8-%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%BB%85%E9%87%8D%E7%82%B9%E5%86%85%E5%AE%B9%EF%BC%89/" title="信息内容安全-复习（仅重点内容）">信息内容安全-复习（仅重点内容）</a><time datetime="2023-05-26T11:15:31.000Z" title="发表于 2023-05-26 19:15:31">2023-05-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/20/%E5%B7%A5%E6%8E%A7%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8-%E5%A4%8D%E4%B9%A0/" title="工控网络安全-复习">工控网络安全-复习</a><time datetime="2023-05-20T11:41:23.000Z" title="发表于 2023-05-20 19:41:23">2023-05-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/15/%E5%B0%8F%E5%B0%8F%E9%AD%94%E6%B3%95-for-UOOC/" title="小小魔法 for UOOC">小小魔法 for UOOC</a><time datetime="2023-05-15T11:47:05.000Z" title="发表于 2023-05-15 19:47:05">2023-05-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By Nanbu</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo-api-w8og.vercel.app',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(init)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo-api-w8og.vercel.app',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
      
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script defer src="/live2d-widget/autoload.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="给我狠狠的学,熬熬熬,肝爆！" data-fontsize="15px" data-random="true" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>